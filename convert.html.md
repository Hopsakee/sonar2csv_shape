# Conversion logic


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Conversion steps

We need to do several processing steps to go from the `sl2` or `sl3`
data to a `csv` and `shape` we can use in our GIS software.

**From depth in meter to bottom height in mNAP**

To convert from depth measurement in meter to bottom height measurement
in mNAP we need to know the height in mNAP from which the depth
measurements were taken. Currently we add this height manually in the
filename in cmNAP. Some examples:

- `2024-07-11_zuiderpark Hoogeveen2_+1075cmnap.sl2`
- `Sonar_2022-04-26_21.07.11beschrijving+0765cmNAP.sl3`

We extract this height from the filename.

The height of the Sonar boot is also stored in the `gps_altitude` column
from the `sl2` and `sl3` files, but we haven‚Äôt yet implemented the
conversion from this height to mNAP height.

**Filter relevant facts**

We only need the facts that have the value ‚Äúprimary‚Äù in the column
‚Äúsurvey‚Äù.

**Transformation to the correct CRS**

The co√∂rdinates in the Sonar files are in crs WGS84 (epsg:4326), we need
to convert those to the crs we use, which is RDN Amersfoort
(epsg:28992). We accomplish that by using the `geopandas` method
`.set_crs` and `.to_crs`.

## Importing modules

We will use [sonarlight](https://github.com/KennethTM/sonarlight) to
read the measurements from the `sl2` or `sl3` files.

<div>

> **Note**
>
> Previously we used
> [sslib](https://github.com/opensounder/python-sllib) to parse the
> sonar files. But this package latest commit was 4 years ago. This
> `sslib` package also has less stars and the `sonarlight` has some neat
> extra features, such as simple conversion to a Pandas dataframe.

</div>

## Load sl3 file for testing.

``` python
sl3_f = Path("../test/Sonar_2022-04-26_21.07.11beschrijving+0765cmNAP.sl3")
```

------------------------------------------------------------------------

### read_sl

>  read_sl (filepath:pathlib.Path)

<table>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>Path</td>
<td>The absolute location of the file to convert</td>
</tr>
<tr>
<td><strong>Returns</strong></td>
<td><strong>Sonar</strong></td>
<td></td>
</tr>
</tbody>
</table>

``` python
sl3_d = read_sl(sl3_f)
sl3_d
```

    Summary of SL3 file:

    - Primary channel with 1320 frames
    - Secondary channel with 1320 frames
    - Downscan channel with 1320 frames
    - Sidescan channel with 1319 frames

    Start time: 2022-04-26 11:08:49.101999998
    End time: 2022-04-26 11:10:19.315000057

    File info: version 3, device 2, blocksize 3200, frame version 10

``` python
type(sl3_d)
```

    sonarlight.sonar_class.Sonar

``` python
sl3_d.df.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">survey</th>
<th data-quarto-table-cell-role="th">datetime</th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">min_range</th>
<th data-quarto-table-cell-role="th">max_range</th>
<th data-quarto-table-cell-role="th">water_depth</th>
<th data-quarto-table-cell-role="th">gps_speed</th>
<th data-quarto-table-cell-role="th">gps_heading</th>
<th data-quarto-table-cell-role="th">gps_altitude</th>
<th data-quarto-table-cell-role="th">bottom_index</th>
<th data-quarto-table-cell-role="th">frames</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">1570</td>
<td>174</td>
<td>primary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>36.576000</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1573</td>
<td>174</td>
<td>secondary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>36.576000</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1576</td>
<td>174</td>
<td>downscan</td>
<td>2022-04-26 11:08:49.239000082</td>
<td>674207</td>
<td>6913400</td>
<td>6.076879</td>
<td>52.748746</td>
<td>0.000000</td>
<td>21.945601</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>38</td>
<td>[152, 152, 152, 152, 129, 143, 140, 137, 140, ...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1577</td>
<td>352</td>
<td>sidescan</td>
<td>2022-04-26 11:08:49.240000010</td>
<td>674207</td>
<td>6913400</td>
<td>6.076879</td>
<td>52.748746</td>
<td>-39.989758</td>
<td>39.989758</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>21</td>
<td>[42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1579</td>
<td>175</td>
<td>primary</td>
<td>2022-04-26 11:08:49.249000072</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>3.992880</td>
<td>0.609836</td>
<td>0.122237</td>
<td>0.247439</td>
<td>-1.91</td>
<td>469</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
</tr>
</tbody>
</table>

</div>

``` python
sl3_df = sl3_d.df
```

<div>

> **ü§ñ AI chat: Notes to use `gps_altitude` column from `sl3`-file
> instead of extrachting the height of the measurement instrument from
> the filename**
>
> ------------------------------------------------------------------------
>
> ü§î *The `sl3_df_sml` dataframe also has a column `gps_altitude`. Can
> you explain what this probably is. Given that longitude and latitude
> are given in the WGS84 coordinate system?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> The `gps_altitude` column is likely the **altitude (elevation) above
> the WGS84 ellipsoid**, measured in meters.
>
> In the WGS84 coordinate system, GPS devices typically provide three
> coordinates: - Longitude and latitude (horizontal position) -
> Altitude/elevation (vertical position)
>
> This GPS altitude is usually the height above the WGS84 reference
> ellipsoid (a mathematical model of Earth‚Äôs shape), not the height
> above sea level or above a local datum like NAP.
>
> Looking at your data, the `gps_altitude` values are around 12.19
> meters. This would be the height of the GPS antenna (on your sonar
> boat) above the WGS84 ellipsoid at that location.
>
> Is this different from the height information you‚Äôre extracting from
> the filename (like ‚Äú+1075cmnap‚Äù)? What do you think the relationship
> might be between these two height measurements?
>
> ------------------------------------------------------------------------
>
> ü§î *Great. How can I transform this `gps_altitude` to mNAP as used in
> the RDnew Amersfoort system (epsg:28992)?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> However, there‚Äôs an important distinction to make here:
>
> **GPS altitude and coordinate system transformations work differently
> than horizontal coordinates.**
>
> When you transform longitude/latitude from WGS84 (epsg:4326) to RD New
> (epsg:28992) using `.to_crs()`, it handles the horizontal position
> transformation well. But the vertical component (altitude) is trickier
> because:
>
> 1.  GPS altitude is height above the WGS84 ellipsoid
> 2.  NAP (Normaal Amsterdams Peil) is a height above mean sea level
> 3.  These two reference surfaces don‚Äôt have a simple constant offset -
>     the difference varies by location
>
> To properly convert GPS altitude to mNAP, you typically need a **geoid
> model** or a transformation grid specific to the Netherlands (like
> NLGEO2018 or similar). This accounts for the local variations between
> the ellipsoid and the geoid (mean sea level).
>
> Do you have access to such a transformation tool, or is there a reason
> you‚Äôre interested in converting the GPS altitude? I notice you‚Äôre
> already extracting the NAP height from the filename - is that serving
> a different purpose?
>
> ------------------------------------------------------------------------
>
> ü§î *It would be good if we could skip the NAP height from the
> filename. Since that is a manual proces. Which may give errors or be
> forgotten when the file is uploaded.*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> That makes sense - automating this would definitely reduce errors and
> make the workflow more robust!
>
> To convert GPS altitude (WGS84 ellipsoid height) to mNAP, you‚Äôll need
> to apply a geoid correction. In the Netherlands, the standard approach
> is to use the **RDNAPTRANS** transformation, which includes both
> horizontal (RD) and vertical (NAP) transformations.
>
> Python libraries that can handle this include: - **pyproj** - can
> handle vertical transformations with the right geoid model - **PROJ**
> (the underlying library) - supports compound CRS transformations
>
> The key is to use a compound coordinate reference system that includes
> both horizontal and vertical components. For the Netherlands, you‚Äôd
> want something like EPSG:7415 (RD New + NAP height).
>
> Have you used `pyproj` before, or would you like to explore how to set
> up this transformation? It will involve a few steps beyond the simple
> `.to_crs()` you‚Äôre currently using.

</div>

## Convert Pandas DataFrame to GeoDataFrame

<div>

> **ü§ñ AI chat: Pandas Dataframe to GeoDataFrame**
>
> ------------------------------------------------------------------------
>
> ü§î *How to convert the pandas dataframe `sl2df_sml` to a
> geodataframe?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> To convert your pandas DataFrame `sl2df_sml` to a GeoDataFrame, you
> need to create geometry objects from your coordinate columns. Since
> you have `longitude` and `latitude` columns, you can use those to
> create Point geometries.
>
> Here‚Äôs how you‚Äôd approach it:
>
> ``` python
> gdf = geopandas.GeoDataFrame(sl2df_sml, geometry=geopandas.points_from_xy(sl2df_sml.longitude, sl2df_sml.latitude))
> ```
>
> This creates Point geometries from your longitude/latitude columns.
> However, you‚Äôll also want to set the coordinate reference system (CRS)
> since these are WGS84 coordinates. Would you like to try writing that
> part yourself, or would you like a hint about which method to use?

</div>

``` python
gdf = gpd.GeoDataFrame(sl3_df, geometry=gpd.points_from_xy(sl3_df.longitude, sl3_df.latitude))
```

``` python
gdf = gdf.set_crs(epsg=4326)
```

``` python
gdf.crs
```

    <Geographic 2D CRS: EPSG:4326>
    Name: WGS 84
    Axis Info [ellipsoidal]:
    - Lat[north]: Geodetic latitude (degree)
    - Lon[east]: Geodetic longitude (degree)
    Area of Use:
    - name: World.
    - bounds: (-180.0, -90.0, 180.0, 90.0)
    Datum: World Geodetic System 1984 ensemble
    - Ellipsoid: WGS 84
    - Prime Meridian: Greenwich

``` python
gdf = gdf.to_crs(epsg=28992)
```

``` python
gdf.crs
```

    <Projected CRS: EPSG:28992>
    Name: Amersfoort / RD New
    Axis Info [cartesian]:
    - X[east]: Easting (metre)
    - Y[north]: Northing (metre)
    Area of Use:
    - name: Netherlands - onshore, including Waddenzee, Dutch Wadden Islands and 12-mile offshore coastal zone.
    - bounds: (3.2, 50.75, 7.22, 53.7)
    Coordinate Operation:
    - name: RD New
    - method: Oblique Stereographic
    Datum: Amersfoort
    - Ellipsoid: Bessel 1841
    - Prime Meridian: Greenwich

<div>

> **ü§ñ AI regex chat**
>
> ------------------------------------------------------------------------
>
> ü§î \_I want to build a regex to extract the height in all of the
> following cases:
>
> `measurements_-720cmnap.sl2` `measurements_+720cmNap.sl3`
> `measurements_-1720cmnap.sl3` `measurements-1720cmnap.sl3`
> `measurements+20cmNAP.sl2` `measurements+20CMNAP.sl2`\_
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Great! You want to extract the height value (including the sign) from
> those filenames. Let‚Äôs break down what patterns you need to match:
>
> - Either a leading `+` or `-` sign
> - One or more digits
> - Followed by `cmnap` (case-insensitive)
>
> You only need the number with its sign.
>
> To extract this pattern with regex, you‚Äôll need to use Python‚Äôs `re`
> module. Here‚Äôs the approach:
>
> **Pattern components:** - `[+-]` matches either + or - - `\d+` matches
> one or more digits - `(?=cmnap)` is a lookahead that checks for
> ‚Äúcmnap‚Äù (case-insensitive) without including it in the match
>
> You‚Äôll want to use `re.search()` to find the pattern in the filename
> string, and use the `re.IGNORECASE` flag to handle different
> capitalizations.
>
> Would you like to try writing the regex pattern yourself, or would you
> like me to show you an example?

</div>

``` python
rgx = r"[+-]\d+(?=cmnap)"
```

``` python
int(re.search(rgx, str(sl3_f), flags=re.IGNORECASE)[0])
```

    765

------------------------------------------------------------------------

### extract_height

>  extract_height (sl_filepath:pathlib.Path,
>                      re_ptrn:str='[+-]?\\d+(?=cmnap)')

*Extract height from the filename in cmNAP*

<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 25%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>sl_filepath</td>
<td>Path</td>
<td></td>
<td>The absolute location of the file to convert</td>
</tr>
<tr>
<td>re_ptrn</td>
<td>str</td>
<td>[+-]?(?=cmnap)</td>
<td></td>
</tr>
<tr>
<td><strong>Returns</strong></td>
<td><strong>int</strong></td>
<td></td>
<td><strong>The height of the measurement station in cm above
NAP</strong></td>
</tr>
</tbody>
</table>

Test function `extract_height`

``` python
(extract_height(Path("/some/where/afen22e34_1823cmNAP.sl2")),
extract_height(Path("/some/where/afen22e34-1823cmNAP.sl2")),
extract_height(Path("/some/where/afen22e34br_-1823cmNAP.sl2")))
```

    (1823, -1823, -1823)

``` python
def slx2gdf(
    sl_filepath: Path, # The absolute location of the file to convert
    msrmnt_height: int, # Height of the measurement instrument at time of taking the measurements
    to_crs: str = "epsg:28992", # epsg code of crs to transform the co√∂rdinates to
    )->gpd:
    "Convert a sl2 or sl3 file to a GeoDataFrame with the given crs."
    s = Sonar(str(sl_filepath))
    df = s.df
    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))
    gdf = gdf.set_crs(epsg=4326)
    return gdf.to_crs(to_crs)
```

Test function `slx2gdf`

``` python
sl3_gdf = slx2gdf(sl3_f, 1823)
```

``` python
"water_depth" in gdf.columns
```

    True

``` python
sl3_gdf.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">survey</th>
<th data-quarto-table-cell-role="th">datetime</th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">min_range</th>
<th data-quarto-table-cell-role="th">max_range</th>
<th data-quarto-table-cell-role="th">water_depth</th>
<th data-quarto-table-cell-role="th">gps_speed</th>
<th data-quarto-table-cell-role="th">gps_heading</th>
<th data-quarto-table-cell-role="th">gps_altitude</th>
<th data-quarto-table-cell-role="th">bottom_index</th>
<th data-quarto-table-cell-role="th">frames</th>
<th data-quarto-table-cell-role="th">geometry</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">1570</td>
<td>174</td>
<td>primary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>36.576000</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1573</td>
<td>174</td>
<td>secondary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>36.576000</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1576</td>
<td>174</td>
<td>downscan</td>
<td>2022-04-26 11:08:49.239000082</td>
<td>674207</td>
<td>6913400</td>
<td>6.076879</td>
<td>52.748746</td>
<td>0.000000</td>
<td>21.945601</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>38</td>
<td>[152, 152, 152, 152, 129, 143, 140, 137, 140, ...</td>
<td>POINT (201567.685 529267.472)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1577</td>
<td>352</td>
<td>sidescan</td>
<td>2022-04-26 11:08:49.240000010</td>
<td>674207</td>
<td>6913400</td>
<td>6.076879</td>
<td>52.748746</td>
<td>-39.989758</td>
<td>39.989758</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>21</td>
<td>[42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...</td>
<td>POINT (201567.685 529267.472)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1579</td>
<td>175</td>
<td>primary</td>
<td>2022-04-26 11:08:49.249000072</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>3.992880</td>
<td>0.609836</td>
<td>0.122237</td>
<td>0.247439</td>
<td>-1.91</td>
<td>469</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
</tbody>
</table>

</div>

## Building filter on GeoDataFrame

``` python
sl3_gdf_pr = sl3_gdf[sl3_gdf["survey"]=="primary"]
sl3_gdf_pr.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">survey</th>
<th data-quarto-table-cell-role="th">datetime</th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">min_range</th>
<th data-quarto-table-cell-role="th">max_range</th>
<th data-quarto-table-cell-role="th">water_depth</th>
<th data-quarto-table-cell-role="th">gps_speed</th>
<th data-quarto-table-cell-role="th">gps_heading</th>
<th data-quarto-table-cell-role="th">gps_altitude</th>
<th data-quarto-table-cell-role="th">bottom_index</th>
<th data-quarto-table-cell-role="th">frames</th>
<th data-quarto-table-cell-role="th">geometry</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">1570</td>
<td>174</td>
<td>primary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>36.57600</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1579</td>
<td>175</td>
<td>primary</td>
<td>2022-04-26 11:08:49.249000072</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.609836</td>
<td>0.122237</td>
<td>0.247439</td>
<td>-1.91</td>
<td>469</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1587</td>
<td>176</td>
<td>primary</td>
<td>2022-04-26 11:08:49.290999889</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.609836</td>
<td>0.118954</td>
<td>0.248092</td>
<td>-1.91</td>
<td>469</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1596</td>
<td>177</td>
<td>primary</td>
<td>2022-04-26 11:08:49.378000021</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.612811</td>
<td>0.114456</td>
<td>0.248715</td>
<td>-1.91</td>
<td>471</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1604</td>
<td>178</td>
<td>primary</td>
<td>2022-04-26 11:08:49.423000097</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.612811</td>
<td>0.107427</td>
<td>0.249878</td>
<td>-1.91</td>
<td>471</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
</tbody>
</table>

</div>

<div>

> **ü§ñ AI chat: pd.df a value is trying to be set on a copy of a slice
> from a DataFrame**
>
> ------------------------------------------------------------------------
>
> ü§î *Please explain the DataFrame warning.*
>
> ``` python
> sl2_gdf_pr['bottom_height'] = 12.53/100 - sl2_gdf_pr['water_depth']
> ```
>
> ``` text
> /app/data/.local/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: 
> A value is trying to be set on a copy of a slice from a DataFrame.
> Try using .loc[row_indexer,col_indexer] = value instead
>
> See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
>   super().__setitem__(key, value)
> ```
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> This warning occurs because of how you created `sl2df_sml_pr`. When
> you filtered the dataframe with:
>
> ``` python
> sl2df_sml_pr = sl2df_sml[sl2df_sml["survey"]=="primary"]
> ```
>
> Pandas doesn‚Äôt know if this created a **copy** of the data or just a
> **view** (reference) to the original data. When you then try to add a
> new column to `sl2df_sml_pr`, pandas warns you that changes might
> unexpectedly affect the original `sl2df_sml` dataframe (or might not
> work at all).
>
> **The solution:** Use `.copy()` to explicitly create a new dataframe:
>
> ``` python
> sl2df_sml_pr = sl2df_sml[sl2df_sml["survey"]=="primary"].copy()
> ```
>
> Or use `.loc[]` for the assignment as the warning suggests.
>
> Would you like to try fixing this yourself, or do you have questions
> about why this happens?

</div>

``` python
sl3_gdf_pr = sl3_gdf[sl3_gdf["survey"]=="primary"].copy()
```

``` python
sl3_gdf_pr['bottom_height'] = 12.53/100 - sl3_gdf_pr['water_depth']
```

``` python
sl3_gdf_pr.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">survey</th>
<th data-quarto-table-cell-role="th">datetime</th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">min_range</th>
<th data-quarto-table-cell-role="th">max_range</th>
<th data-quarto-table-cell-role="th">water_depth</th>
<th data-quarto-table-cell-role="th">gps_speed</th>
<th data-quarto-table-cell-role="th">gps_heading</th>
<th data-quarto-table-cell-role="th">gps_altitude</th>
<th data-quarto-table-cell-role="th">bottom_index</th>
<th data-quarto-table-cell-role="th">frames</th>
<th data-quarto-table-cell-role="th">geometry</th>
<th data-quarto-table-cell-role="th">bottom_height</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">1570</td>
<td>174</td>
<td>primary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>36.57600</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
<td>POINT (201568.299 529266.871)</td>
<td>-0.481561</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1579</td>
<td>175</td>
<td>primary</td>
<td>2022-04-26 11:08:49.249000072</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.609836</td>
<td>0.122237</td>
<td>0.247439</td>
<td>-1.91</td>
<td>469</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
<td>-0.484536</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1587</td>
<td>176</td>
<td>primary</td>
<td>2022-04-26 11:08:49.290999889</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.609836</td>
<td>0.118954</td>
<td>0.248092</td>
<td>-1.91</td>
<td>469</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
<td>-0.484536</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1596</td>
<td>177</td>
<td>primary</td>
<td>2022-04-26 11:08:49.378000021</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.612811</td>
<td>0.114456</td>
<td>0.248715</td>
<td>-1.91</td>
<td>471</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
<td>-0.487511</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1604</td>
<td>178</td>
<td>primary</td>
<td>2022-04-26 11:08:49.423000097</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.612811</td>
<td>0.107427</td>
<td>0.249878</td>
<td>-1.91</td>
<td>471</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
<td>-0.487511</td>
</tr>
</tbody>
</table>

</div>

<div>

> **ü§ñAI chat: `latitude` and `longitude`**
>
> ------------------------------------------------------------------------
>
> ü§î *How can I check the precision of the `latitude` and `longitude`
> columns?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> To check the precision of the `latitude` and `longitude` columns, you
> can look at how many decimal places the values have. Here are a few
> approaches:
>
> **Option 1:** Convert to string and check the length after the decimal
> point:
>
> ``` python
> sl2_gdf_pr['latitude'].astype(str).str.split('.').str[1].str.len()
> ```
>
> **Option 2:** Calculate the smallest difference between consecutive
> values to see the resolution.
>
> **Option 3:** Look at a few sample values directly to visually inspect
> the decimal places.
>
> Which approach would you like to try first, or do you have a specific
> reason for checking the precision?
>
> ------------------------------------------------------------------------
>
> ü§î *‚ÄúDo I understand correctly that the visualisation from a Dataframe
> shows the complete numbers and doesn‚Äôt truncate?‚Äù*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Not quite - pandas DataFrames **do truncate** displayed values by
> default for readability, even though the full precision is stored
> internally.
>
> You can check the actual precision by:
>
> 1.  Using `.iloc[0]` to access a single value directly (this shows
>     more precision than the table view)
> 2.  Checking pandas display options with
>     `pd.get_option('display.precision')`
> 3.  Setting display precision higher with
>     `pd.set_option('display.precision', 10)` (or whatever number you
>     want)
>
> Try accessing a single latitude value directly - does it show more
> decimal places than what you see in the table display?Not quite -
> pandas DataFrames **do** truncate displayed values by default! When
> you see a value like `52.71157` in the display, there might actually
> be more decimal places that aren‚Äôt being shown.
>
> To see the full precision of the values, you can:
>
> 1.  Use `pd.set_option('display.precision', 20)` to show more decimal
>     places in the display
> 2.  Access individual values directly with `.iloc[]` or `.loc[]` and
>     print them
> 3.  Check the actual dtype of the column - if it‚Äôs `float64`, it can
>     store about 15-17 significant decimal digits
>
> Would you like to try one of these methods to see the full precision
> of your latitude/longitude values?

</div>

``` python
sl3_gdf_pr['longitude'].iloc[0]
```

    np.float64(6.076888166251876)

<div>

> **ü§ñ AI Chat: Geometry column**
>
> ------------------------------------------------------------------------
>
> ü§î *How can I check if the precision of the `geometry` column is the
> same?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Good question! The `geometry` column contains Point objects (not just
> numbers), so you need to extract the coordinates from the geometry
> first.
>
> You can access the x and y coordinates of a Point geometry using `.x`
> and `.y` attributes:
>
> ``` python
> sl2_gdf_pr['geometry'].iloc[0].x
> sl2_gdf_pr['geometry'].iloc[0].y
> ```
>
> This will show you the precision of the transformed coordinates (in RD
> New/EPSG:28992). Try it and compare - do they have similar precision
> to the original longitude/latitude values?

</div>

``` python
sl3_gdf_pr['geometry'].iloc[0].x
sl3_gdf_pr['geometry'].iloc[0].y
```

    529266.87106734

<div>

> **ü§ñ AI chat: Check meaning of `bottom_index` column**
>
> ------------------------------------------------------------------------
>
> ü§î *I think that all measurements with the same ‚Äúbottom_index‚Äù also
> have the same longitude and latitude and water_depth. How can I check
> that assumption?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Good hypothesis! To check this, you could group by `bottom_index` and
> see if the values within each group are all the same.
>
> One approach is to use `.groupby()` with `.nunique()` (number of
> unique values). If a column has only 1 unique value per group, then
> all values in that group are identical.
>
> Try something like:
>
> ``` python
> sl2df_sml_pr.groupby('bottom_index')[['longitude', 'latitude', 'water_depth']].nunique()
> ```
>
> This will show you how many unique values exist for each column within
> each `bottom_index` group. What do you expect to see if your
> assumption is correct?

</div>

``` python
sl3_gdf[sl3_gdf["survey"]=="primary"].groupby('bottom_index')[['longitude', 'latitude', 'water_depth']].nunique()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">water_depth</th>
</tr>
<tr>
<th data-quarto-table-cell-role="th">bottom_index</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">50</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">328</td>
<td>1</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">330</td>
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">332</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">333</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1001</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1005</td>
<td>2</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1007</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1008</td>
<td>3</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1011</td>
<td>1</td>
<td>2</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>322 rows √ó 3 columns</p>
</div>

``` python
sl3_d.df[sl3_d.df["bottom_index"]==475]
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">survey</th>
<th data-quarto-table-cell-role="th">datetime</th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">min_range</th>
<th data-quarto-table-cell-role="th">max_range</th>
<th data-quarto-table-cell-role="th">water_depth</th>
<th data-quarto-table-cell-role="th">gps_speed</th>
<th data-quarto-table-cell-role="th">gps_heading</th>
<th data-quarto-table-cell-role="th">gps_altitude</th>
<th data-quarto-table-cell-role="th">bottom_index</th>
<th data-quarto-table-cell-role="th">frames</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">9536</td>
<td>1111</td>
<td>primary</td>
<td>2022-04-26 11:09:52.848999977</td>
<td>674198</td>
<td>6913407</td>
<td>6.076798</td>
<td>52.748784</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.617507</td>
<td>0.162986</td>
<td>4.224975</td>
<td>-5.5</td>
<td>475</td>
<td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9539</td>
<td>1111</td>
<td>secondary</td>
<td>2022-04-26 11:09:52.848999977</td>
<td>674198</td>
<td>6913407</td>
<td>6.076798</td>
<td>52.748784</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.617507</td>
<td>0.162986</td>
<td>4.224975</td>
<td>-5.5</td>
<td>475</td>
<td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9544</td>
<td>1112</td>
<td>primary</td>
<td>2022-04-26 11:09:52.894999981</td>
<td>674198</td>
<td>6913407</td>
<td>6.076798</td>
<td>52.748784</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.617507</td>
<td>0.164213</td>
<td>4.223330</td>
<td>-5.5</td>
<td>475</td>
<td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">9547</td>
<td>1112</td>
<td>secondary</td>
<td>2022-04-26 11:09:52.894999981</td>
<td>674198</td>
<td>6913407</td>
<td>6.076798</td>
<td>52.748784</td>
<td>0.0</td>
<td>3.99288</td>
<td>0.617507</td>
<td>0.164213</td>
<td>4.223330</td>
<td>-5.5</td>
<td>475</td>
<td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>
</tr>
</tbody>
</table>

</div>

<div>

> **ü§ñ AI chat: Further investigate `bottom_index`**
>
> ------------------------------------------------------------------------
>
> ü§î *It is mostly true that the same bottom_index is the same location
> and depth. But not always. So we must filter the resulting table on
> same locations. Could we use something like `.unique` to only keep
> those points that have a unique `longitude`, `latitude` combination?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Yes, good thinking! You can use `.drop_duplicates()` to keep only
> unique combinations of longitude and latitude.
>
> The method would look like:
>
> ``` python
> df_unique = df.drop_duplicates(subset=['longitude', 'latitude'])
> ```
>
> This keeps the first occurrence of each unique longitude/latitude pair
> and removes the rest.
>
> Would you like to try applying this to your filtered primary survey
> data? Or do you have questions about how `drop_duplicates()` works?

</div>

``` python
def clean_gdf(
    gdf: gpd.GeoDataFrame, # GeoDataFrame from sl2gdf
    msrmnt_height: int, # Height of measurement instrument in cm above NAP
    ) -> gpd.GeoDataFrame: # Cleaned GeoDataFrame with bottom_height column
    "Filter primary survey data, remove duplicates, and calculate bottom height in mNAP"
    gdf_primary = gdf[gdf["survey"] == "primary"].copy()
    gdf_unique = gdf_primary.drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])
    gdf_unique.loc[:, 'bottom_height'] = msrmnt_height / 100 - gdf_unique['water_depth']
    return gdf_unique
```

``` python
cln_gdf = clean_gdf(sl3_gdf, 1823)
```

    /app/data/.local/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      super().__setitem__(key, value)

<div>

> **`.drop_duplicates()` warning: trying to be set on a copy of a
> slice**
>
> ------------------------------------------------------------------------
>
> ü§î *Why do I get this warning in the function `clean_gdf`?*
>
> ``` python
> cln_gdf = clean_gdf(sl4_gdf, 1823)
> ```
>
> ``` text
> /home/jelle/code/sonar2csv_shape/.venv/lib/python3.11/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: 
> A value is trying to be set on a copy of a slice from a DataFrame.
> Try using .loc[row_indexer,col_indexer] = value instead
>
> See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
>   super().__setitem__(key, value)
> ```
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> The warning occurs because `.drop_duplicates()` might return a view
> rather than a copy, and then you‚Äôre trying to modify it.
>
> The fix is to add `.copy()` after `.drop_duplicates()`:
>
> ``` python
> gdf_unique = gdf_primary.drop_duplicates(subset=['longitude', 'latitude', 'water_depth']).copy()
> ```
>
> This ensures `gdf_unique` is definitely a new dataframe, not a view.
> Would you like to update the function with this change? \_\_\_ ü§î *Is
> this really the best way? We now create a bunch of copies in memory,
> just to clean the dataframe.*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> You‚Äôre absolutely right to question this! Creating multiple copies is
> inefficient, especially with large datasets.
>
> A better approach would be to chain the operations and only make one
> copy at the end:
>
> ``` python
> gdf_clean = (gdf[gdf["survey"] == "primary"]
>              .drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])
>              .copy())
> gdf_clean['bottom_height'] = msrmnt_height / 100 - gdf_clean['water_depth']
> ```
>
> Or even more efficiently, you could use `.assign()` to add the column
> without triggering the warning:
>
> ``` python
> return (gdf[gdf["survey"] == "primary"]
>         .drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])
>         .assign(bottom_height=lambda x: msrmnt_height / 100 - x['water_depth']))
> ```
>
> This creates only one copy and avoids the warning entirely. Would you
> like to try refactoring your function with one of these approaches?
>
> ------------------------------------------------------------------------
>
> ü§î *There also is another issue. Sometimes we do have the same
> location (e.g.¬†‚Äòlongitude‚Äô, ‚Äòlatitude‚Äô) but different heights. This is
> probably due to the fact that the depth meter creates a pulse almost
> every second, but the location is rounded off to respectively 6 and 5
> numbers after the diggit. So I actually want to drop the long-lat
> duplicates and take the mean of the merged ‚Äòwater_depth‚Äô.*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Good observation! So you want to group by longitude and latitude, then
> take the mean of `water_depth` for each unique location.
>
> You can use `.groupby()` with `.agg()` to accomplish this. The tricky
> part is handling the geometry column and deciding what to do with the
> other columns (like datetime, gps_speed, etc.).
>
> For the geometry, you could keep the first point since they‚Äôre all at
> the same location. For other columns, you‚Äôll need to decide: keep
> first? mean? something else?
>
> Would you like to try writing the groupby operation yourself, or would
> you like me to show you an example of how to structure it?

</div>

Test grouping of measurements based on location and creating several
aggregations columns with different aggregation functions

``` python
gdf_grpd = gdf.groupby(['longitude', 'latitude'], as_index=False).agg(
    mean_depth=pd.NamedAgg(column="water_depth", aggfunc="mean"),
    min_depth=pd.NamedAgg(column="water_depth", aggfunc="min"),
    max_depth=pd.NamedAgg(column="water_depth", aggfunc="max"),
    geometery=pd.NamedAgg(column="geometry", aggfunc="first"),
    datetime=pd.NamedAgg(column="datetime", aggfunc="mean")
)
```

``` python
gdf_grpd.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">mean_depth</th>
<th data-quarto-table-cell-role="th">min_depth</th>
<th data-quarto-table-cell-role="th">max_depth</th>
<th data-quarto-table-cell-role="th">geometery</th>
<th data-quarto-table-cell-role="th">datetime</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>6.07678</td>
<td>52.748746</td>
<td>0.941204</td>
<td>0.932471</td>
<td>0.950051</td>
<td>POINT (201560.99 529267.408)</td>
<td>2022-04-26 11:10:03.997620224</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>6.07678</td>
<td>52.748752</td>
<td>0.991693</td>
<td>0.947595</td>
<td>1.031126</td>
<td>POINT (201560.985 529268.016)</td>
<td>2022-04-26 11:10:02.506777600</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>6.07678</td>
<td>52.748757</td>
<td>1.068617</td>
<td>1.042099</td>
<td>1.078859</td>
<td>POINT (201560.979 529268.623)</td>
<td>2022-04-26 11:10:01.312600064</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>6.07678</td>
<td>52.748762</td>
<td>1.067053</td>
<td>1.051482</td>
<td>1.077630</td>
<td>POINT (201560.973 529269.23)</td>
<td>2022-04-26 11:10:00.477333504</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>6.07678</td>
<td>52.748768</td>
<td>0.970447</td>
<td>0.867511</td>
<td>1.051482</td>
<td>POINT (201560.967 529269.837)</td>
<td>2022-04-26 11:09:59.711977216</td>
</tr>
</tbody>
</table>

</div>

``` python
def clean_gdf(
    gdf: gpd.GeoDataFrame, # GeoDataFrame from sl2gdf
    msrmnt_height: int, # Height of measurement instrument in cm above NAP
    ) -> gpd.GeoDataFrame: # Cleaned GeoDataFrame with bottom_height column
    "Filter primary survey data, remove duplicates, and calculate bottom height in mNAP"
    return (gdf[gdf["survey"]=="primary"]
            .drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])
            .assign(bottom_height=lambda x: msrmnt_height / 100 - x['water_depth']))
```

``` python
def clean_gdf(
    gdf: gpd.GeoDataFrame, # GeoDataFrame from sl2gdf
    msrmnt_height: int, # Height of measurement instrument in cm above NAP
    ) -> gpd.GeoDataFrame: # Cleaned GeoDataFrame with bottom_height column
    "Filter primary survey data, remove duplicates, and calculate bottom height in mNAP"
    return (gdf[gdf["survey"]=="primary"]
            .groupby(['longitude', 'latitude'], as_index=False).agg(
                mean_depth=pd.NamedAgg(column="water_depth", aggfunc="mean"),
                min_depth=pd.NamedAgg(column="water_depth", aggfunc="min"),
                max_depth=pd.NamedAgg(column="water_depth", aggfunc="max"),
                geometry=pd.NamedAgg(column="geometry", aggfunc="first"),
                datetime=pd.NamedAgg(column="datetime", aggfunc="mean")
            )
            .assign(bottom_height=lambda x: msrmnt_height / 100 - x['mean_depth']))
```

<div>

> **ü§ñ AI chat: Aggregation of geodataframe returns a pandas dataframe**
>
> ------------------------------------------------------------------------
>
> ü§î *When I use `clean_gdf` the returned object is a Pandas Dataframe,
> not a GeoDataFrame. This probably is the result of the `.groupby`
> method that uses the `agg` method. How can I solve this? I want a
> GeoDataFrame?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Good catch! When you use `.groupby().agg()` on a GeoDataFrame, it
> returns a regular DataFrame, losing the GeoDataFrame properties.
>
> To fix this, you need to convert it back to a GeoDataFrame after the
> aggregation. You can use:
>
> ``` python
> gpd.GeoDataFrame(result, geometry='geometry', crs=gdf.crs)
> ```
>
> Where `result` is your aggregated dataframe. You‚Äôll need to make sure
> to preserve the original CRS from the input GeoDataFrame.
>
> Would you like to try adding this conversion to your `clean_gdf`
> function?

</div>

------------------------------------------------------------------------

### clean_gdf

>  clean_gdf (gdf:geopandas.geodataframe.GeoDataFrame, msrmnt_height:int)

*Filter primary survey data, remove duplicates, and calculate bottom
height in mNAP*

<table>
<colgroup>
<col style="width: 9%" />
<col style="width: 38%" />
<col style="width: 52%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>gdf</td>
<td>GeoDataFrame</td>
<td>GeoDataFrame from sl2gdf</td>
</tr>
<tr>
<td>msrmnt_height</td>
<td>int</td>
<td>Height of measurement instrument in cm above NAP</td>
</tr>
<tr>
<td><strong>Returns</strong></td>
<td><strong>GeoDataFrame</strong></td>
<td><strong>Cleaned GeoDataFrame with bottom_height column</strong></td>
</tr>
</tbody>
</table>

``` python
cln_gdf = clean_gdf(sl3_gdf, 1823)
```

``` python
type(cln_gdf)
```

    geopandas.geodataframe.GeoDataFrame

``` python
cln_gdf.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">mean_depth</th>
<th data-quarto-table-cell-role="th">min_depth</th>
<th data-quarto-table-cell-role="th">max_depth</th>
<th data-quarto-table-cell-role="th">geometry</th>
<th data-quarto-table-cell-role="th">datetime</th>
<th data-quarto-table-cell-role="th">bottom_height</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">0</td>
<td>6.076780</td>
<td>52.748757</td>
<td>1.073326</td>
<td>1.069168</td>
<td>1.078859</td>
<td>POINT (201560.979 529268.623)</td>
<td>2022-04-26 11:10:01.221999872</td>
<td>17.156673</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1</td>
<td>6.076780</td>
<td>52.748762</td>
<td>1.068734</td>
<td>1.051482</td>
<td>1.077630</td>
<td>POINT (201560.973 529269.23)</td>
<td>2022-04-26 11:10:00.517230848</td>
<td>17.161266</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">2</td>
<td>6.076780</td>
<td>52.748768</td>
<td>0.969534</td>
<td>0.867511</td>
<td>1.051482</td>
<td>POINT (201560.967 529269.837)</td>
<td>2022-04-26 11:09:59.692999936</td>
<td>17.260466</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">3</td>
<td>6.076780</td>
<td>52.748773</td>
<td>0.861626</td>
<td>0.858684</td>
<td>0.867511</td>
<td>POINT (201560.961 529270.444)</td>
<td>2022-04-26 11:09:59.201000192</td>
<td>17.368374</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">4</td>
<td>6.076789</td>
<td>52.748752</td>
<td>0.958502</td>
<td>0.932471</td>
<td>0.999739</td>
<td>POINT (201561.593 529268.021)</td>
<td>2022-04-26 11:10:02.960588288</td>
<td>17.271498</td>
</tr>
</tbody>
</table>

</div>

``` python
cln_gdf['geometry'].iloc[0].x
```

    201560.97882739094

<div>

> **ü§ñ AI chat: Checking for needed columns**
>
> ------------------------------------------------------------------------
>
> ü§î *I also would like to check if the Dataframe that is created from
> the sl2 or sl3 file contains the needed columns in the needed
> datatype. Should I write a function to check that? Should I add the
> checks within an existing function? Should I use Pydantic?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Good question about validation! You have a few options:
>
> 1.  **Separate validation function** - keeps concerns separated,
>     reusable
> 2.  **Add checks within existing functions** - catches issues early
>     where they matter
> 3.  **Use Pydantic** - more robust, but adds dependency and complexity
>
> For your case, I‚Äôd suggest starting simple: add basic checks within
> your existing functions (like `sl2gdf` or `clean_gdf`) to verify the
> required columns exist. Something like:
>
> ``` python
> required_cols = ['longitude', 'latitude', 'water_depth', 'survey']
> if not all(col in df.columns for col in required_cols):
>     raise ValueError(f"Missing required columns...")
> ```
>
> Pydantic would be great if you‚Äôre building a larger system with
> complex validation needs, but might be overkill here.
>
> Which approach feels right for your use case? Are you expecting the
> sonar file format to be stable, or do you need robust validation?

</div>

------------------------------------------------------------------------

### slx2gdf

>  slx2gdf (sl_filepath:pathlib.Path, to_crs:str='epsg:28992',
>               survey_fltr:str='primary')

*Convert a sl2 or sl3 file to a GeoDataFrame with the given crs.*

<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 25%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>sl_filepath</td>
<td>Path</td>
<td></td>
<td>The absolute location of the file to convert</td>
</tr>
<tr>
<td>to_crs</td>
<td>str</td>
<td>epsg:28992</td>
<td>epsg code of crs to transform the co√∂rdinates to</td>
</tr>
<tr>
<td>survey_fltr</td>
<td>str</td>
<td>primary</td>
<td>Filter measurement facts on survey value</td>
</tr>
<tr>
<td><strong>Returns</strong></td>
<td><strong>geopandas</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

``` python
gdf = slx2gdf(sl3_f)
gdf.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&#10;    .dataframe tbody tr th {
        vertical-align: top;
    }
&#10;    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe" data-quarto-postprocess="true" data-border="1">
<thead>
<tr style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">survey</th>
<th data-quarto-table-cell-role="th">datetime</th>
<th data-quarto-table-cell-role="th">x</th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">longitude</th>
<th data-quarto-table-cell-role="th">latitude</th>
<th data-quarto-table-cell-role="th">min_range</th>
<th data-quarto-table-cell-role="th">max_range</th>
<th data-quarto-table-cell-role="th">water_depth</th>
<th data-quarto-table-cell-role="th">gps_speed</th>
<th data-quarto-table-cell-role="th">gps_heading</th>
<th data-quarto-table-cell-role="th">gps_altitude</th>
<th data-quarto-table-cell-role="th">bottom_index</th>
<th data-quarto-table-cell-role="th">frames</th>
<th data-quarto-table-cell-role="th">geometry</th>
</tr>
</thead>
<tbody>
<tr>
<td data-quarto-table-cell-role="th">1570</td>
<td>174</td>
<td>primary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>36.576000</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1573</td>
<td>174</td>
<td>secondary</td>
<td>2022-04-26 11:08:49.101999998</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>36.576000</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>50</td>
<td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1576</td>
<td>174</td>
<td>downscan</td>
<td>2022-04-26 11:08:49.239000082</td>
<td>674207</td>
<td>6913400</td>
<td>6.076879</td>
<td>52.748746</td>
<td>0.000000</td>
<td>21.945601</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>38</td>
<td>[152, 152, 152, 152, 129, 143, 140, 137, 140, ...</td>
<td>POINT (201567.685 529267.472)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1577</td>
<td>352</td>
<td>sidescan</td>
<td>2022-04-26 11:08:49.240000010</td>
<td>674207</td>
<td>6913400</td>
<td>6.076879</td>
<td>52.748746</td>
<td>-39.989758</td>
<td>39.989758</td>
<td>0.606861</td>
<td>0.127106</td>
<td>0.246756</td>
<td>-1.91</td>
<td>21</td>
<td>[42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...</td>
<td>POINT (201567.685 529267.472)</td>
</tr>
<tr>
<td data-quarto-table-cell-role="th">1579</td>
<td>175</td>
<td>primary</td>
<td>2022-04-26 11:08:49.249000072</td>
<td>674208</td>
<td>6913399</td>
<td>6.076888</td>
<td>52.748741</td>
<td>0.000000</td>
<td>3.992880</td>
<td>0.609836</td>
<td>0.122237</td>
<td>0.247439</td>
<td>-1.91</td>
<td>469</td>
<td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>
<td>POINT (201568.299 529266.871)</td>
</tr>
</tbody>
</table>

</div>

``` python
gdf.crs
```

    <Projected CRS: EPSG:28992>
    Name: Amersfoort / RD New
    Axis Info [cartesian]:
    - X[east]: Easting (metre)
    - Y[north]: Northing (metre)
    Area of Use:
    - name: Netherlands - onshore, including Waddenzee, Dutch Wadden Islands and 12-mile offshore coastal zone.
    - bounds: (3.2, 50.75, 7.22, 53.7)
    Coordinate Operation:
    - name: RD New
    - method: Oblique Stereographic
    Datum: Amersfoort
    - Ellipsoid: Bessel 1841
    - Prime Meridian: Greenwich

``` python
gdf['geometry'].iloc[0].x
```

    201568.2991979634

<div>

> **ü§ñ AI chat: Keep x and y coordinates in csv export**
>
> ------------------------------------------------------------------------
>
> ü§î *I don‚Äôt want to drop the geometry column completely. I want to
> keep the x and y coordinates in a x and y column. How do I do that?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> You can extract the x and y coordinates from the geometry column
> before exporting to CSV. Here‚Äôs how:
>
> ``` python
> gdf['x'] = gdf.geometry.x
> gdf['y'] = gdf.geometry.y
> ```
>
> Then when you export to CSV, you can drop just the geometry column:
>
> ``` python
> gdf.drop(columns='geometry').to_csv(folder_out / f"{fn}.csv", index=False)
> ```
>
> Would you like to add this to your `export_gdf` function?

</div>

------------------------------------------------------------------------

### export_gdf

>  export_gdf (gdf:geopandas.geodataframe.GeoDataFrame, fn:str,
>                  folder_out:pathlib.Path, esri_shp:bool=True, csv:bool=True,
>                  geopckg:bool=True)

*Deze functie doet iets*

<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 25%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>gdf</td>
<td>GeoDataFrame</td>
<td></td>
<td>GeoDataFrame to be saved</td>
</tr>
<tr>
<td>fn</td>
<td>str</td>
<td></td>
<td>Filename of the GeoDataFrame without extension</td>
</tr>
<tr>
<td>folder_out</td>
<td>Path</td>
<td></td>
<td>Absolute path to folder where files can be saved</td>
</tr>
<tr>
<td>esri_shp</td>
<td>bool</td>
<td>True</td>
<td>Save GeoDataFrame to Esri shapefile?</td>
</tr>
<tr>
<td>csv</td>
<td>bool</td>
<td>True</td>
<td>Save GeoDataFrame to comma seperated file?</td>
</tr>
<tr>
<td>geopckg</td>
<td>bool</td>
<td>True</td>
<td>Save GeoDataFrame to geopackage?</td>
</tr>
<tr>
<td><strong>Returns</strong></td>
<td><strong>None</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

``` python
sl3_f.stem
```

    'Sonar_2022-04-26_21.07.11beschrijving+0765cmNAP'

``` python
export_gdf(cln_gdf, sl3_f.stem, Path("../test/"))
```

    /tmp/ipykernel_105/1576217988.py:10: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.
      if esri_shp: gdf.to_file(folder_out / f"{fn}.shp")
    /app/data/.local/lib/python3.12/site-packages/pyogrio/raw.py:723: RuntimeWarning: Field datetime create as date field, though DateTime requested.
      ogr_write(
    /app/data/.local/lib/python3.12/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'bottom_height' to 'bottom_hei'
      ogr_write(

------------------------------------------------------------------------

### process_sonar_file

>  process_sonar_file (sl_filepath:pathlib.Path, folder_out:pathlib.Path,
>                          to_crs:str='epsg:28992')

*Process sonar file: extract height, convert to GeoDataFrame, clean, and
export*

<table>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>sl_filepath</td>
<td>Path</td>
<td></td>
<td>Path to sl2 or sl3 file</td>
</tr>
<tr>
<td>folder_out</td>
<td>Path</td>
<td></td>
<td>Output folder for exported files</td>
</tr>
<tr>
<td>to_crs</td>
<td>str</td>
<td>epsg:28992</td>
<td>Target CRS</td>
</tr>
<tr>
<td><strong>Returns</strong></td>
<td><strong>None</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

``` python
process_sonar_file(sl3_f, Path("../test"))
```

    /tmp/ipykernel_105/1576217988.py:10: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.
      if esri_shp: gdf.to_file(folder_out / f"{fn}.shp")
    /app/data/.local/lib/python3.12/site-packages/pyogrio/raw.py:723: RuntimeWarning: Field datetime create as date field, though DateTime requested.
      ogr_write(
    /app/data/.local/lib/python3.12/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'bottom_height' to 'bottom_hei'
      ogr_write(

<div>

> **ü§ñ AI chat: Difference between `gdf.loc[:, 'y'] =` and
> `gdf['y'] =`?**
>
> ------------------------------------------------------------------------
>
> ü§î *Can you explain what the difference is ‚Äúunder the hood‚Äù between
> `gdf.loc[:, 'y'] =` and just `gdf['y'] =`?*
>
> ##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->
>
> Great question! Here‚Äôs what‚Äôs happening under the hood:
>
> **`gdf['y'] = ...`** (chained indexing) - Pandas first evaluates
> `gdf['y']`, which *might* return a view or a copy (pandas can‚Äôt always
> tell) - Then it tries to assign to that result - Because pandas isn‚Äôt
> sure if you‚Äôre modifying the original or a copy, it warns you
>
> **`gdf.loc[:, 'y'] = ...`** (explicit indexing) - This is a single
> operation that tells pandas: ‚ÄúI want to modify the original DataFrame
> at all rows (`:`) and column `'y'`‚Äù - Pandas knows you intend to
> modify the original, so no ambiguity, no warning
>
> The `.loc[]` approach is more explicit about your intent to modify the
> DataFrame in place, which helps pandas optimize the operation and
> avoid unnecessary copies.
>
> Does that clarify the difference?

</div>
