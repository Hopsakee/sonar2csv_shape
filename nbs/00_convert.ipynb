{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6c0cf3",
   "metadata": {},
   "source": [
    "# Conversion logic\n",
    "\n",
    "> Module containing the reading and conversion logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b60596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11811fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fa64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sonarlight import Sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35730d96",
   "metadata": {},
   "source": [
    "## Conversion steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93947b6",
   "metadata": {},
   "source": [
    "We need to do several processing steps to go from the `sl2` or `sl3` data to a `csv` and `shape` we can use in our GIS software.\n",
    "\n",
    "**From depth in meter to bottom height in mNAP**\n",
    "\n",
    "To convert from depth measurement in meter to bottom height measurement in mNAP we need to know the height in mNAP from which the depth measurements were taken. Currently we add this height manually in the filename in cmNAP. Some examples:\n",
    "\n",
    "- `2024-07-11_zuiderpark Hoogeveen2_+1075cmnap.sl2`\n",
    "- `Sonar_2022-04-26_21.07.11beschrijving+0765cmNAP.sl3`\n",
    "\n",
    "We extract this height from the filename.\n",
    "\n",
    "The height of the Sonar boot is also stored in the `gps_altitude` column from the `sl2` and `sl3` files, but we haven't yet implemented the conversion from this height to mNAP height.\n",
    "\n",
    "**Filter relevant facts**\n",
    "\n",
    "We only need the facts that have the value \"primary\" in the column \"survey\".\n",
    "\n",
    "**Transformation to the correct CRS**\n",
    "\n",
    "The coÃ¶rdinates in the Sonar files are in crs WGS84 (epsg:4326), we need to convert those to the crs we use, which is RDN Amersfoort (epsg:28992).\n",
    "We accomplish that by using the `geopandas` method `.set_crs` and `.to_crs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0b9fd",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fd299",
   "metadata": {},
   "source": [
    "We will use [sonarlight](https://github.com/KennethTM/sonarlight) to read the measurements from the `sl2` or `sl3` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f7eea",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Previously we used [sslib](https://github.com/opensounder/python-sllib) to parse the sonar files. But this package latest commit was 4 years ago. This `sslib` package also has less stars and the `sonarlight` has some neat extra features, such as simple conversion to a Pandas dataframe.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b8607",
   "metadata": {},
   "source": [
    "## Load sl3 file for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl3_f = Path(\"../test/Sonar_2022-04-26_21.07.11beschrijving+0765cmNAP.sl3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_sl(\n",
    "    filepath: Path # The absolute location of the file to convert\n",
    "    )->Sonar:\n",
    "    return Sonar(str(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summary of SL3 file:\n",
       "\n",
       "- Primary channel with 1320 frames\n",
       "- Secondary channel with 1320 frames\n",
       "- Downscan channel with 1320 frames\n",
       "- Sidescan channel with 1319 frames\n",
       "\n",
       "Start time: 2022-04-26 11:08:49.101999998\n",
       "End time: 2022-04-26 11:10:19.315000057\n",
       "\n",
       "File info: version 3, device 2, blocksize 3200, frame version 10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_d = read_sl(sl3_f)\n",
    "sl3_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ff2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sonarlight.sonar_class.Sonar"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sl3_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0589d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey</th>\n",
       "      <th>datetime</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>min_range</th>\n",
       "      <th>max_range</th>\n",
       "      <th>water_depth</th>\n",
       "      <th>gps_speed</th>\n",
       "      <th>gps_heading</th>\n",
       "      <th>gps_altitude</th>\n",
       "      <th>bottom_index</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>174</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.576000</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>174</td>\n",
       "      <td>secondary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.576000</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>174</td>\n",
       "      <td>downscan</td>\n",
       "      <td>2022-04-26 11:08:49.239000082</td>\n",
       "      <td>674207</td>\n",
       "      <td>6913400</td>\n",
       "      <td>6.076879</td>\n",
       "      <td>52.748746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.945601</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>38</td>\n",
       "      <td>[152, 152, 152, 152, 129, 143, 140, 137, 140, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>352</td>\n",
       "      <td>sidescan</td>\n",
       "      <td>2022-04-26 11:08:49.240000010</td>\n",
       "      <td>674207</td>\n",
       "      <td>6913400</td>\n",
       "      <td>6.076879</td>\n",
       "      <td>52.748746</td>\n",
       "      <td>-39.989758</td>\n",
       "      <td>39.989758</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>21</td>\n",
       "      <td>[42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>175</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.249000072</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.992880</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.122237</td>\n",
       "      <td>0.247439</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>469</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     survey                      datetime       x        y  \\\n",
       "1570  174    primary 2022-04-26 11:08:49.101999998  674208  6913399   \n",
       "1573  174  secondary 2022-04-26 11:08:49.101999998  674208  6913399   \n",
       "1576  174   downscan 2022-04-26 11:08:49.239000082  674207  6913400   \n",
       "1577  352   sidescan 2022-04-26 11:08:49.240000010  674207  6913400   \n",
       "1579  175    primary 2022-04-26 11:08:49.249000072  674208  6913399   \n",
       "\n",
       "      longitude   latitude  min_range  max_range  water_depth  gps_speed  \\\n",
       "1570   6.076888  52.748741   0.000000  36.576000     0.606861   0.127106   \n",
       "1573   6.076888  52.748741   0.000000  36.576000     0.606861   0.127106   \n",
       "1576   6.076879  52.748746   0.000000  21.945601     0.606861   0.127106   \n",
       "1577   6.076879  52.748746 -39.989758  39.989758     0.606861   0.127106   \n",
       "1579   6.076888  52.748741   0.000000   3.992880     0.609836   0.122237   \n",
       "\n",
       "      gps_heading  gps_altitude  bottom_index  \\\n",
       "1570     0.246756         -1.91            50   \n",
       "1573     0.246756         -1.91            50   \n",
       "1576     0.246756         -1.91            38   \n",
       "1577     0.246756         -1.91            21   \n",
       "1579     0.247439         -1.91           469   \n",
       "\n",
       "                                                 frames  \n",
       "1570  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...  \n",
       "1573  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...  \n",
       "1576  [152, 152, 152, 152, 129, 143, 140, 137, 140, ...  \n",
       "1577  [42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...  \n",
       "1579  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_d.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1038ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl3_df = sl3_d.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e1a7e",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Notes to use `gps_altitude` column from `sl3`-file instead of extrachting the height of the measurement instrument from the filename\n",
    "\n",
    "___\n",
    "ðŸ¤” _The `sl3_df_sml` dataframe also has a column `gps_altitude`. Can you explain what this probably is. Given that longitude and latitude are given in the WGS84 coordinate system?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The `gps_altitude` column is likely the **altitude (elevation) above the WGS84 ellipsoid**, measured in meters. \n",
    "\n",
    "In the WGS84 coordinate system, GPS devices typically provide three coordinates:\n",
    "- Longitude and latitude (horizontal position)\n",
    "- Altitude/elevation (vertical position)\n",
    "\n",
    "This GPS altitude is usually the height above the WGS84 reference ellipsoid (a mathematical model of Earth's shape), not the height above sea level or above a local datum like NAP.\n",
    "\n",
    "Looking at your data, the `gps_altitude` values are around 12.19 meters. This would be the height of the GPS antenna (on your sonar boat) above the WGS84 ellipsoid at that location.\n",
    "\n",
    "Is this different from the height information you're extracting from the filename (like \"+1075cmnap\")? What do you think the relationship might be between these two height measurements?\n",
    "\n",
    "___\n",
    "ðŸ¤” _Great. How can I transform this `gps_altitude` to mNAP as used in the RDnew Amersfoort system (epsg:28992)?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "However, there's an important distinction to make here:\n",
    "\n",
    "**GPS altitude and coordinate system transformations work differently than horizontal coordinates.**\n",
    "\n",
    "When you transform longitude/latitude from WGS84 (epsg:4326) to RD New (epsg:28992) using `.to_crs()`, it handles the horizontal position transformation well. But the vertical component (altitude) is trickier because:\n",
    "\n",
    "1. GPS altitude is height above the WGS84 ellipsoid\n",
    "2. NAP (Normaal Amsterdams Peil) is a height above mean sea level\n",
    "3. These two reference surfaces don't have a simple constant offset - the difference varies by location\n",
    "\n",
    "To properly convert GPS altitude to mNAP, you typically need a **geoid model** or a transformation grid specific to the Netherlands (like NLGEO2018 or similar). This accounts for the local variations between the ellipsoid and the geoid (mean sea level).\n",
    "\n",
    "Do you have access to such a transformation tool, or is there a reason you're interested in converting the GPS altitude? I notice you're already extracting the NAP height from the filename - is that serving a different purpose?\n",
    "\n",
    "___\n",
    "ðŸ¤” _It would be good if we could skip the NAP height from the filename. Since that is a manual proces. Which may give errors or be forgotten when the file is uploaded._\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That makes sense - automating this would definitely reduce errors and make the workflow more robust!\n",
    "\n",
    "To convert GPS altitude (WGS84 ellipsoid height) to mNAP, you'll need to apply a geoid correction. In the Netherlands, the standard approach is to use the **RDNAPTRANS** transformation, which includes both horizontal (RD) and vertical (NAP) transformations.\n",
    "\n",
    "Python libraries that can handle this include:\n",
    "- **pyproj** - can handle vertical transformations with the right geoid model\n",
    "- **PROJ** (the underlying library) - supports compound CRS transformations\n",
    "\n",
    "The key is to use a compound coordinate reference system that includes both horizontal and vertical components. For the Netherlands, you'd want something like EPSG:7415 (RD New + NAP height).\n",
    "\n",
    "Have you used `pyproj` before, or would you like to explore how to set up this transformation? It will involve a few steps beyond the simple `.to_crs()` you're currently using.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4722c",
   "metadata": {},
   "source": [
    "## Convert Pandas DataFrame to GeoDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829719b",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Pandas Dataframe to GeoDataFrame\n",
    "\n",
    "___\n",
    "ðŸ¤” _How to convert the pandas dataframe `sl2df_sml` to a geodataframe?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "To convert your pandas DataFrame `sl2df_sml` to a GeoDataFrame, you need to create geometry objects from your coordinate columns. Since you have `longitude` and `latitude` columns, you can use those to create Point geometries.\n",
    "\n",
    "Here's how you'd approach it:\n",
    "\n",
    "```python\n",
    "gdf = geopandas.GeoDataFrame(sl2df_sml, geometry=geopandas.points_from_xy(sl2df_sml.longitude, sl2df_sml.latitude))\n",
    "```\n",
    "\n",
    "This creates Point geometries from your longitude/latitude columns. However, you'll also want to set the coordinate reference system (CRS) since these are WGS84 coordinates. Would you like to try writing that part yourself, or would you like a hint about which method to use?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(sl3_df, geometry=gpd.points_from_xy(sl3_df.longitude, sl3_df.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29aff19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World.\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42010a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.to_crs(epsg=28992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89782c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:28992>\n",
       "Name: Amersfoort / RD New\n",
       "Axis Info [cartesian]:\n",
       "- X[east]: Easting (metre)\n",
       "- Y[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: Netherlands - onshore, including Waddenzee, Dutch Wadden Islands and 12-mile offshore coastal zone.\n",
       "- bounds: (3.2, 50.75, 7.22, 53.7)\n",
       "Coordinate Operation:\n",
       "- name: RD New\n",
       "- method: Oblique Stereographic\n",
       "Datum: Amersfoort\n",
       "- Ellipsoid: Bessel 1841\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6456e",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI regex chat\n",
    "\n",
    "___\n",
    "ðŸ¤” _I want to build a regex to extract the height in all of the following cases:\n",
    "\n",
    "`measurements_-720cmnap.sl2`\n",
    "`measurements_+720cmNap.sl3`\n",
    "`measurements_-1720cmnap.sl3`\n",
    "`measurements-1720cmnap.sl3`\n",
    "`measurements+20cmNAP.sl2`\n",
    "`measurements+20CMNAP.sl2`_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! You want to extract the height value (including the sign) from those filenames. Let's break down what patterns you need to match:\n",
    "\n",
    "- Either a leading `+` or `-` sign\n",
    "- One or more digits\n",
    "- Followed by `cmnap` (case-insensitive)\n",
    "\n",
    "You only need the number with its sign.\n",
    "\n",
    "To extract this pattern with regex, you'll need to use Python's `re` module. Here's the approach:\n",
    "\n",
    "**Pattern components:**\n",
    "- `[+-]` matches either + or -\n",
    "- `\\d+` matches one or more digits\n",
    "- `(?=cmnap)` is a lookahead that checks for \"cmnap\" (case-insensitive) without including it in the match\n",
    "\n",
    "You'll want to use `re.search()` to find the pattern in the filename string, and use the `re.IGNORECASE` flag to handle different capitalizations.\n",
    "\n",
    "Would you like to try writing the regex pattern yourself, or would you like me to show you an example?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972fd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgx = r\"[+-]\\d+(?=cmnap)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c291c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(re.search(rgx, str(sl3_f), flags=re.IGNORECASE)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46610e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_height(\n",
    "    sl_filepath: Path, # The absolute location of the file to convert\n",
    "    re_ptrn: str=r\"[+-]?\\d+(?=cmnap)\"\n",
    "    )->int: # The height of the measurement station in cm above NAP\n",
    "    \"Extract height from the filename in cmNAP\"\n",
    "    if 'cmnap' not in str(sl_filepath).lower():\n",
    "        raise ValueError(\"The filename must contain the height of the Sonar boot at time of measurement in 'cmNAP' at the end of the filename (e.g. 'example_description_+1050cmNAP.sl2')\")\n",
    "    return int(re.search(re_ptrn, str(sl_filepath), flags=re.IGNORECASE)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d235b3",
   "metadata": {},
   "source": [
    "Test function `extract_height`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1c79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1823, -1823, -1823)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(extract_height(Path(\"/some/where/afen22e34_1823cmNAP.sl2\")),\n",
    "extract_height(Path(\"/some/where/afen22e34-1823cmNAP.sl2\")),\n",
    "extract_height(Path(\"/some/where/afen22e34br_-1823cmNAP.sl2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d571d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slx2gdf(\n",
    "    sl_filepath: Path, # The absolute location of the file to convert\n",
    "    msrmnt_height: int, # Height of the measurement instrument at time of taking the measurements\n",
    "    to_crs: str = \"epsg:28992\", # epsg code of crs to transform the coÃ¶rdinates to\n",
    "    )->gpd:\n",
    "    \"Convert a sl2 or sl3 file to a GeoDataFrame with the given crs.\"\n",
    "    s = Sonar(str(sl_filepath))\n",
    "    df = s.df\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "    gdf = gdf.set_crs(epsg=4326)\n",
    "    return gdf.to_crs(to_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d44e4f",
   "metadata": {},
   "source": [
    "Test function `slx2gdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b384e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl3_gdf = slx2gdf(sl3_f, 1823)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e56ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"water_depth\" in gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6fdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey</th>\n",
       "      <th>datetime</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>min_range</th>\n",
       "      <th>max_range</th>\n",
       "      <th>water_depth</th>\n",
       "      <th>gps_speed</th>\n",
       "      <th>gps_heading</th>\n",
       "      <th>gps_altitude</th>\n",
       "      <th>bottom_index</th>\n",
       "      <th>frames</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>174</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.576000</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>174</td>\n",
       "      <td>secondary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.576000</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>174</td>\n",
       "      <td>downscan</td>\n",
       "      <td>2022-04-26 11:08:49.239000082</td>\n",
       "      <td>674207</td>\n",
       "      <td>6913400</td>\n",
       "      <td>6.076879</td>\n",
       "      <td>52.748746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.945601</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>38</td>\n",
       "      <td>[152, 152, 152, 152, 129, 143, 140, 137, 140, ...</td>\n",
       "      <td>POINT (201567.685 529267.472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>352</td>\n",
       "      <td>sidescan</td>\n",
       "      <td>2022-04-26 11:08:49.240000010</td>\n",
       "      <td>674207</td>\n",
       "      <td>6913400</td>\n",
       "      <td>6.076879</td>\n",
       "      <td>52.748746</td>\n",
       "      <td>-39.989758</td>\n",
       "      <td>39.989758</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>21</td>\n",
       "      <td>[42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...</td>\n",
       "      <td>POINT (201567.685 529267.472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>175</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.249000072</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.992880</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.122237</td>\n",
       "      <td>0.247439</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>469</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     survey                      datetime       x        y  \\\n",
       "1570  174    primary 2022-04-26 11:08:49.101999998  674208  6913399   \n",
       "1573  174  secondary 2022-04-26 11:08:49.101999998  674208  6913399   \n",
       "1576  174   downscan 2022-04-26 11:08:49.239000082  674207  6913400   \n",
       "1577  352   sidescan 2022-04-26 11:08:49.240000010  674207  6913400   \n",
       "1579  175    primary 2022-04-26 11:08:49.249000072  674208  6913399   \n",
       "\n",
       "      longitude   latitude  min_range  max_range  water_depth  gps_speed  \\\n",
       "1570   6.076888  52.748741   0.000000  36.576000     0.606861   0.127106   \n",
       "1573   6.076888  52.748741   0.000000  36.576000     0.606861   0.127106   \n",
       "1576   6.076879  52.748746   0.000000  21.945601     0.606861   0.127106   \n",
       "1577   6.076879  52.748746 -39.989758  39.989758     0.606861   0.127106   \n",
       "1579   6.076888  52.748741   0.000000   3.992880     0.609836   0.122237   \n",
       "\n",
       "      gps_heading  gps_altitude  bottom_index  \\\n",
       "1570     0.246756         -1.91            50   \n",
       "1573     0.246756         -1.91            50   \n",
       "1576     0.246756         -1.91            38   \n",
       "1577     0.246756         -1.91            21   \n",
       "1579     0.247439         -1.91           469   \n",
       "\n",
       "                                                 frames  \\\n",
       "1570  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...   \n",
       "1573  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...   \n",
       "1576  [152, 152, 152, 152, 129, 143, 140, 137, 140, ...   \n",
       "1577  [42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...   \n",
       "1579  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "\n",
       "                           geometry  \n",
       "1570  POINT (201568.299 529266.871)  \n",
       "1573  POINT (201568.299 529266.871)  \n",
       "1576  POINT (201567.685 529267.472)  \n",
       "1577  POINT (201567.685 529267.472)  \n",
       "1579  POINT (201568.299 529266.871)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e66ac",
   "metadata": {},
   "source": [
    "## Building filter on GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319fa4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey</th>\n",
       "      <th>datetime</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>min_range</th>\n",
       "      <th>max_range</th>\n",
       "      <th>water_depth</th>\n",
       "      <th>gps_speed</th>\n",
       "      <th>gps_heading</th>\n",
       "      <th>gps_altitude</th>\n",
       "      <th>bottom_index</th>\n",
       "      <th>frames</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>174</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.57600</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>175</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.249000072</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.122237</td>\n",
       "      <td>0.247439</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>469</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>176</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.290999889</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.118954</td>\n",
       "      <td>0.248092</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>469</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>177</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.378000021</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.612811</td>\n",
       "      <td>0.114456</td>\n",
       "      <td>0.248715</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>471</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>178</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.423000097</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.612811</td>\n",
       "      <td>0.107427</td>\n",
       "      <td>0.249878</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>471</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   survey                      datetime       x        y  longitude  \\\n",
       "1570  174  primary 2022-04-26 11:08:49.101999998  674208  6913399   6.076888   \n",
       "1579  175  primary 2022-04-26 11:08:49.249000072  674208  6913399   6.076888   \n",
       "1587  176  primary 2022-04-26 11:08:49.290999889  674208  6913399   6.076888   \n",
       "1596  177  primary 2022-04-26 11:08:49.378000021  674208  6913399   6.076888   \n",
       "1604  178  primary 2022-04-26 11:08:49.423000097  674208  6913399   6.076888   \n",
       "\n",
       "       latitude  min_range  max_range  water_depth  gps_speed  gps_heading  \\\n",
       "1570  52.748741        0.0   36.57600     0.606861   0.127106     0.246756   \n",
       "1579  52.748741        0.0    3.99288     0.609836   0.122237     0.247439   \n",
       "1587  52.748741        0.0    3.99288     0.609836   0.118954     0.248092   \n",
       "1596  52.748741        0.0    3.99288     0.612811   0.114456     0.248715   \n",
       "1604  52.748741        0.0    3.99288     0.612811   0.107427     0.249878   \n",
       "\n",
       "      gps_altitude  bottom_index  \\\n",
       "1570         -1.91            50   \n",
       "1579         -1.91           469   \n",
       "1587         -1.91           469   \n",
       "1596         -1.91           471   \n",
       "1604         -1.91           471   \n",
       "\n",
       "                                                 frames  \\\n",
       "1570  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...   \n",
       "1579  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "1587  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "1596  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "1604  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "\n",
       "                           geometry  \n",
       "1570  POINT (201568.299 529266.871)  \n",
       "1579  POINT (201568.299 529266.871)  \n",
       "1587  POINT (201568.299 529266.871)  \n",
       "1596  POINT (201568.299 529266.871)  \n",
       "1604  POINT (201568.299 529266.871)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_gdf_pr = sl3_gdf[sl3_gdf[\"survey\"]==\"primary\"]\n",
    "sl3_gdf_pr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e2388",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: pd.df a value is trying to be set on a copy of a slice from a DataFrame\n",
    "\n",
    "___\n",
    "ðŸ¤” _Please explain the DataFrame warning._\n",
    "\n",
    "```python\n",
    "sl2_gdf_pr['bottom_height'] = 12.53/100 - sl2_gdf_pr['water_depth']\n",
    "```\n",
    "\n",
    "```text\n",
    "/app/data/.local/lib/python3.12/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "  super().__setitem__(key, value)\n",
    "```\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "This warning occurs because of how you created `sl2df_sml_pr`. When you filtered the dataframe with:\n",
    "\n",
    "```python\n",
    "sl2df_sml_pr = sl2df_sml[sl2df_sml[\"survey\"]==\"primary\"]\n",
    "```\n",
    "\n",
    "Pandas doesn't know if this created a **copy** of the data or just a **view** (reference) to the original data. When you then try to add a new column to `sl2df_sml_pr`, pandas warns you that changes might unexpectedly affect the original `sl2df_sml` dataframe (or might not work at all).\n",
    "\n",
    "**The solution:** Use `.copy()` to explicitly create a new dataframe:\n",
    "\n",
    "```python\n",
    "sl2df_sml_pr = sl2df_sml[sl2df_sml[\"survey\"]==\"primary\"].copy()\n",
    "```\n",
    "\n",
    "Or use `.loc[]` for the assignment as the warning suggests. \n",
    "\n",
    "Would you like to try fixing this yourself, or do you have questions about why this happens?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e7d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl3_gdf_pr = sl3_gdf[sl3_gdf[\"survey\"]==\"primary\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b293e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl3_gdf_pr['bottom_height'] = 12.53/100 - sl3_gdf_pr['water_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c7f8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey</th>\n",
       "      <th>datetime</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>min_range</th>\n",
       "      <th>max_range</th>\n",
       "      <th>water_depth</th>\n",
       "      <th>gps_speed</th>\n",
       "      <th>gps_heading</th>\n",
       "      <th>gps_altitude</th>\n",
       "      <th>bottom_index</th>\n",
       "      <th>frames</th>\n",
       "      <th>geometry</th>\n",
       "      <th>bottom_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>174</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.57600</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "      <td>-0.481561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>175</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.249000072</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.122237</td>\n",
       "      <td>0.247439</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>469</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "      <td>-0.484536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>176</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.290999889</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.118954</td>\n",
       "      <td>0.248092</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>469</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "      <td>-0.484536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>177</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.378000021</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.612811</td>\n",
       "      <td>0.114456</td>\n",
       "      <td>0.248715</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>471</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "      <td>-0.487511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>178</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.423000097</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.612811</td>\n",
       "      <td>0.107427</td>\n",
       "      <td>0.249878</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>471</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "      <td>-0.487511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   survey                      datetime       x        y  longitude  \\\n",
       "1570  174  primary 2022-04-26 11:08:49.101999998  674208  6913399   6.076888   \n",
       "1579  175  primary 2022-04-26 11:08:49.249000072  674208  6913399   6.076888   \n",
       "1587  176  primary 2022-04-26 11:08:49.290999889  674208  6913399   6.076888   \n",
       "1596  177  primary 2022-04-26 11:08:49.378000021  674208  6913399   6.076888   \n",
       "1604  178  primary 2022-04-26 11:08:49.423000097  674208  6913399   6.076888   \n",
       "\n",
       "       latitude  min_range  max_range  water_depth  gps_speed  gps_heading  \\\n",
       "1570  52.748741        0.0   36.57600     0.606861   0.127106     0.246756   \n",
       "1579  52.748741        0.0    3.99288     0.609836   0.122237     0.247439   \n",
       "1587  52.748741        0.0    3.99288     0.609836   0.118954     0.248092   \n",
       "1596  52.748741        0.0    3.99288     0.612811   0.114456     0.248715   \n",
       "1604  52.748741        0.0    3.99288     0.612811   0.107427     0.249878   \n",
       "\n",
       "      gps_altitude  bottom_index  \\\n",
       "1570         -1.91            50   \n",
       "1579         -1.91           469   \n",
       "1587         -1.91           469   \n",
       "1596         -1.91           471   \n",
       "1604         -1.91           471   \n",
       "\n",
       "                                                 frames  \\\n",
       "1570  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...   \n",
       "1579  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "1587  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "1596  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "1604  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "\n",
       "                           geometry  bottom_height  \n",
       "1570  POINT (201568.299 529266.871)      -0.481561  \n",
       "1579  POINT (201568.299 529266.871)      -0.484536  \n",
       "1587  POINT (201568.299 529266.871)      -0.484536  \n",
       "1596  POINT (201568.299 529266.871)      -0.487511  \n",
       "1604  POINT (201568.299 529266.871)      -0.487511  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_gdf_pr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178b81e",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤–AI chat: `latitude` and `longitude`\n",
    "\n",
    "___\n",
    "ðŸ¤” _How can I check the precision of the `latitude` and `longitude` columns?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "To check the precision of the `latitude` and `longitude` columns, you can look at how many decimal places the values have. Here are a few approaches:\n",
    "\n",
    "**Option 1:** Convert to string and check the length after the decimal point:\n",
    "```python\n",
    "sl2_gdf_pr['latitude'].astype(str).str.split('.').str[1].str.len()\n",
    "```\n",
    "\n",
    "**Option 2:** Calculate the smallest difference between consecutive values to see the resolution.\n",
    "\n",
    "**Option 3:** Look at a few sample values directly to visually inspect the decimal places.\n",
    "\n",
    "Which approach would you like to try first, or do you have a specific reason for checking the precision?\n",
    "\n",
    "___\n",
    "\n",
    "ðŸ¤” _\"Do I understand correctly that the visualisation from a Dataframe shows the complete numbers and doesn't truncate?\"_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Not quite - pandas DataFrames **do truncate** displayed values by default for readability, even though the full precision is stored internally.\n",
    "\n",
    "You can check the actual precision by:\n",
    "\n",
    "1. Using `.iloc[0]` to access a single value directly (this shows more precision than the table view)\n",
    "2. Checking pandas display options with `pd.get_option('display.precision')`\n",
    "3. Setting display precision higher with `pd.set_option('display.precision', 10)` (or whatever number you want)\n",
    "\n",
    "Try accessing a single latitude value directly - does it show more decimal places than what you see in the table display?Not quite - pandas DataFrames **do** truncate displayed values by default! When you see a value like `52.71157` in the display, there might actually be more decimal places that aren't being shown.\n",
    "\n",
    "To see the full precision of the values, you can:\n",
    "\n",
    "1. Use `pd.set_option('display.precision', 20)` to show more decimal places in the display\n",
    "2. Access individual values directly with `.iloc[]` or `.loc[]` and print them\n",
    "3. Check the actual dtype of the column - if it's `float64`, it can store about 15-17 significant decimal digits\n",
    "\n",
    "Would you like to try one of these methods to see the full precision of your latitude/longitude values?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574209dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.076888166251876)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_gdf_pr['longitude'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a846507",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI Chat: Geometry column\n",
    "\n",
    "___\n",
    "ðŸ¤” _How can I check if the precision of the `geometry` column is the same?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question! The `geometry` column contains Point objects (not just numbers), so you need to extract the coordinates from the geometry first.\n",
    "\n",
    "You can access the x and y coordinates of a Point geometry using `.x` and `.y` attributes:\n",
    "\n",
    "```python\n",
    "sl2_gdf_pr['geometry'].iloc[0].x\n",
    "sl2_gdf_pr['geometry'].iloc[0].y\n",
    "```\n",
    "\n",
    "This will show you the precision of the transformed coordinates (in RD New/EPSG:28992). Try it and compare - do they have similar precision to the original longitude/latitude values?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ee39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529266.87106734"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_gdf_pr['geometry'].iloc[0].x\n",
    "sl3_gdf_pr['geometry'].iloc[0].y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb0400",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Check meaning of `bottom_index` column\n",
    "\n",
    "___\n",
    "ðŸ¤” _I think that all measurements with the same \"bottom_index\" also have the same longitude and latitude and water_depth. How can I check that assumption?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good hypothesis! To check this, you could group by `bottom_index` and see if the values within each group are all the same.\n",
    "\n",
    "One approach is to use `.groupby()` with `.nunique()` (number of unique values). If a column has only 1 unique value per group, then all values in that group are identical.\n",
    "\n",
    "Try something like:\n",
    "\n",
    "```python\n",
    "sl2df_sml_pr.groupby('bottom_index')[['longitude', 'latitude', 'water_depth']].nunique()\n",
    "```\n",
    "\n",
    "This will show you how many unique values exist for each column within each `bottom_index` group. What do you expect to see if your assumption is correct?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686dcba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>water_depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bottom_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              longitude  latitude  water_depth\n",
       "bottom_index                                  \n",
       "50                    1         1            1\n",
       "328                   1         2            1\n",
       "330                   2         2            1\n",
       "332                   1         1            1\n",
       "333                   2         2            2\n",
       "...                 ...       ...          ...\n",
       "1001                  1         1            1\n",
       "1005                  2         1            1\n",
       "1007                  1         1            1\n",
       "1008                  3         2            2\n",
       "1011                  1         2            1\n",
       "\n",
       "[322 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_gdf[sl3_gdf[\"survey\"]==\"primary\"].groupby('bottom_index')[['longitude', 'latitude', 'water_depth']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc61d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey</th>\n",
       "      <th>datetime</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>min_range</th>\n",
       "      <th>max_range</th>\n",
       "      <th>water_depth</th>\n",
       "      <th>gps_speed</th>\n",
       "      <th>gps_heading</th>\n",
       "      <th>gps_altitude</th>\n",
       "      <th>bottom_index</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9536</th>\n",
       "      <td>1111</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:09:52.848999977</td>\n",
       "      <td>674198</td>\n",
       "      <td>6913407</td>\n",
       "      <td>6.076798</td>\n",
       "      <td>52.748784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.162986</td>\n",
       "      <td>4.224975</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>475</td>\n",
       "      <td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>1111</td>\n",
       "      <td>secondary</td>\n",
       "      <td>2022-04-26 11:09:52.848999977</td>\n",
       "      <td>674198</td>\n",
       "      <td>6913407</td>\n",
       "      <td>6.076798</td>\n",
       "      <td>52.748784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.162986</td>\n",
       "      <td>4.224975</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>475</td>\n",
       "      <td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9544</th>\n",
       "      <td>1112</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:09:52.894999981</td>\n",
       "      <td>674198</td>\n",
       "      <td>6913407</td>\n",
       "      <td>6.076798</td>\n",
       "      <td>52.748784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.164213</td>\n",
       "      <td>4.223330</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>475</td>\n",
       "      <td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9547</th>\n",
       "      <td>1112</td>\n",
       "      <td>secondary</td>\n",
       "      <td>2022-04-26 11:09:52.894999981</td>\n",
       "      <td>674198</td>\n",
       "      <td>6913407</td>\n",
       "      <td>6.076798</td>\n",
       "      <td>52.748784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.99288</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.164213</td>\n",
       "      <td>4.223330</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>475</td>\n",
       "      <td>[214, 214, 214, 214, 214, 214, 214, 214, 214, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     survey                      datetime       x        y  \\\n",
       "9536  1111    primary 2022-04-26 11:09:52.848999977  674198  6913407   \n",
       "9539  1111  secondary 2022-04-26 11:09:52.848999977  674198  6913407   \n",
       "9544  1112    primary 2022-04-26 11:09:52.894999981  674198  6913407   \n",
       "9547  1112  secondary 2022-04-26 11:09:52.894999981  674198  6913407   \n",
       "\n",
       "      longitude   latitude  min_range  max_range  water_depth  gps_speed  \\\n",
       "9536   6.076798  52.748784        0.0    3.99288     0.617507   0.162986   \n",
       "9539   6.076798  52.748784        0.0    3.99288     0.617507   0.162986   \n",
       "9544   6.076798  52.748784        0.0    3.99288     0.617507   0.164213   \n",
       "9547   6.076798  52.748784        0.0    3.99288     0.617507   0.164213   \n",
       "\n",
       "      gps_heading  gps_altitude  bottom_index  \\\n",
       "9536     4.224975          -5.5           475   \n",
       "9539     4.224975          -5.5           475   \n",
       "9544     4.223330          -5.5           475   \n",
       "9547     4.223330          -5.5           475   \n",
       "\n",
       "                                                 frames  \n",
       "9536  [214, 214, 214, 214, 214, 214, 214, 214, 214, ...  \n",
       "9539  [214, 214, 214, 214, 214, 214, 214, 214, 214, ...  \n",
       "9544  [214, 214, 214, 214, 214, 214, 214, 214, 214, ...  \n",
       "9547  [214, 214, 214, 214, 214, 214, 214, 214, 214, ...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_d.df[sl3_d.df[\"bottom_index\"]==475]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144fb03",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Further investigate `bottom_index`\n",
    "\n",
    "___\n",
    "ðŸ¤” _It is mostly true that the same bottom_index is the same location and depth. But not always. So we must filter the resulting table on same locations. Could we use something like `.unique` to only keep those points that have a unique `longitude`, `latitude` combination?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes, good thinking! You can use `.drop_duplicates()` to keep only unique combinations of longitude and latitude.\n",
    "\n",
    "The method would look like:\n",
    "\n",
    "```python\n",
    "df_unique = df.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "```\n",
    "\n",
    "This keeps the first occurrence of each unique longitude/latitude pair and removes the rest.\n",
    "\n",
    "Would you like to try applying this to your filtered primary survey data? Or do you have questions about how `drop_duplicates()` works?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9647a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gdf(\n",
    "    gdf: gpd.GeoDataFrame, # GeoDataFrame from sl2gdf\n",
    "    msrmnt_height: int, # Height of measurement instrument in cm above NAP\n",
    "    ) -> gpd.GeoDataFrame: # Cleaned GeoDataFrame with bottom_height column\n",
    "    \"Filter primary survey data, remove duplicates, and calculate bottom height in mNAP\"\n",
    "    gdf_primary = gdf[gdf[\"survey\"] == \"primary\"].copy()\n",
    "    gdf_unique = gdf_primary.drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])\n",
    "    gdf_unique.loc[:, 'bottom_height'] = msrmnt_height / 100 - gdf_unique['water_depth']\n",
    "    return gdf_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6adfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jelle/code/sonar2csv_shape/.venv/lib/python3.11/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "cln_gdf = clean_gdf(sl3_gdf, 1823)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5bd44",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## `.drop_duplicates()` warning: trying to be set on a copy of a slice\n",
    "___\n",
    "ðŸ¤” _Why do I get this warning in the function `clean_gdf`?_\n",
    "\n",
    "```python\n",
    "cln_gdf = clean_gdf(sl4_gdf, 1823)\n",
    "```\n",
    "\n",
    "```text\n",
    "/home/jelle/code/sonar2csv_shape/.venv/lib/python3.11/site-packages/geopandas/geodataframe.py:1968: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "  super().__setitem__(key, value)\n",
    "```\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The warning occurs because `.drop_duplicates()` might return a view rather than a copy, and then you're trying to modify it.\n",
    "\n",
    "The fix is to add `.copy()` after `.drop_duplicates()`:\n",
    "\n",
    "```python\n",
    "gdf_unique = gdf_primary.drop_duplicates(subset=['longitude', 'latitude', 'water_depth']).copy()\n",
    "```\n",
    "\n",
    "This ensures `gdf_unique` is definitely a new dataframe, not a view. Would you like to update the function with this change?\n",
    "___\n",
    "ðŸ¤” _Is this really the best way? We now create a bunch of copies in memory, just to clean the dataframe._\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You're absolutely right to question this! Creating multiple copies is inefficient, especially with large datasets.\n",
    "\n",
    "A better approach would be to chain the operations and only make one copy at the end:\n",
    "\n",
    "```python\n",
    "gdf_clean = (gdf[gdf[\"survey\"] == \"primary\"]\n",
    "             .drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])\n",
    "             .copy())\n",
    "gdf_clean['bottom_height'] = msrmnt_height / 100 - gdf_clean['water_depth']\n",
    "```\n",
    "\n",
    "Or even more efficiently, you could use `.assign()` to add the column without triggering the warning:\n",
    "\n",
    "```python\n",
    "return (gdf[gdf[\"survey\"] == \"primary\"]\n",
    "        .drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])\n",
    "        .assign(bottom_height=lambda x: msrmnt_height / 100 - x['water_depth']))\n",
    "```\n",
    "\n",
    "This creates only one copy and avoids the warning entirely. Would you like to try refactoring your function with one of these approaches?\n",
    "\n",
    "___\n",
    "ðŸ¤” _There also is another issue. Sometimes we do have the same location (e.g. 'longitude', 'latitude') but different heights. This is probably due to the fact that the depth meter creates a pulse almost every second, but the location is rounded off to respectively 6 and 5 numbers after the diggit. So I actually want to drop the long-lat duplicates and take the mean of the merged 'water_depth'._\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good observation! So you want to group by longitude and latitude, then take the mean of `water_depth` for each unique location.\n",
    "\n",
    "You can use `.groupby()` with `.agg()` to accomplish this. The tricky part is handling the geometry column and deciding what to do with the other columns (like datetime, gps_speed, etc.).\n",
    "\n",
    "For the geometry, you could keep the first point since they're all at the same location. For other columns, you'll need to decide: keep first? mean? something else?\n",
    "\n",
    "Would you like to try writing the groupby operation yourself, or would you like me to show you an example of how to structure it?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eaa26c",
   "metadata": {},
   "source": [
    "Test grouping of measurements based on location and creating several aggregations columns with different aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc086c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_grpd = gdf.groupby(['longitude', 'latitude'], as_index=False).agg(\n",
    "    mean_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"mean\"),\n",
    "    min_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"min\"),\n",
    "    max_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"max\"),\n",
    "    geometery=pd.NamedAgg(column=\"geometry\", aggfunc=\"first\"),\n",
    "    datetime=pd.NamedAgg(column=\"datetime\", aggfunc=\"mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ac084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>geometery</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.07678</td>\n",
       "      <td>52.748746</td>\n",
       "      <td>0.941204</td>\n",
       "      <td>0.932471</td>\n",
       "      <td>0.950051</td>\n",
       "      <td>POINT (201560.99 529267.408)</td>\n",
       "      <td>2022-04-26 11:10:03.997620224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.07678</td>\n",
       "      <td>52.748752</td>\n",
       "      <td>0.991693</td>\n",
       "      <td>0.947595</td>\n",
       "      <td>1.031126</td>\n",
       "      <td>POINT (201560.985 529268.016)</td>\n",
       "      <td>2022-04-26 11:10:02.506777600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.07678</td>\n",
       "      <td>52.748757</td>\n",
       "      <td>1.068617</td>\n",
       "      <td>1.042099</td>\n",
       "      <td>1.078859</td>\n",
       "      <td>POINT (201560.979 529268.623)</td>\n",
       "      <td>2022-04-26 11:10:01.312600064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.07678</td>\n",
       "      <td>52.748762</td>\n",
       "      <td>1.067053</td>\n",
       "      <td>1.051482</td>\n",
       "      <td>1.077630</td>\n",
       "      <td>POINT (201560.973 529269.23)</td>\n",
       "      <td>2022-04-26 11:10:00.477333504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.07678</td>\n",
       "      <td>52.748768</td>\n",
       "      <td>0.970447</td>\n",
       "      <td>0.867511</td>\n",
       "      <td>1.051482</td>\n",
       "      <td>POINT (201560.967 529269.837)</td>\n",
       "      <td>2022-04-26 11:09:59.711977216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude  mean_depth  min_depth  max_depth  \\\n",
       "0    6.07678  52.748746    0.941204   0.932471   0.950051   \n",
       "1    6.07678  52.748752    0.991693   0.947595   1.031126   \n",
       "2    6.07678  52.748757    1.068617   1.042099   1.078859   \n",
       "3    6.07678  52.748762    1.067053   1.051482   1.077630   \n",
       "4    6.07678  52.748768    0.970447   0.867511   1.051482   \n",
       "\n",
       "                       geometery                      datetime  \n",
       "0   POINT (201560.99 529267.408) 2022-04-26 11:10:03.997620224  \n",
       "1  POINT (201560.985 529268.016) 2022-04-26 11:10:02.506777600  \n",
       "2  POINT (201560.979 529268.623) 2022-04-26 11:10:01.312600064  \n",
       "3   POINT (201560.973 529269.23) 2022-04-26 11:10:00.477333504  \n",
       "4  POINT (201560.967 529269.837) 2022-04-26 11:09:59.711977216  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_grpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gdf(\n",
    "    gdf: gpd.GeoDataFrame, # GeoDataFrame from sl2gdf\n",
    "    msrmnt_height: int, # Height of measurement instrument in cm above NAP\n",
    "    ) -> gpd.GeoDataFrame: # Cleaned GeoDataFrame with bottom_height column\n",
    "    \"Filter primary survey data, remove duplicates, and calculate bottom height in mNAP\"\n",
    "    return (gdf[gdf[\"survey\"]==\"primary\"]\n",
    "            .drop_duplicates(subset=['longitude', 'latitude', 'water_depth'])\n",
    "            .assign(bottom_height=lambda x: msrmnt_height / 100 - x['water_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gdf(\n",
    "    gdf: gpd.GeoDataFrame, # GeoDataFrame from sl2gdf\n",
    "    msrmnt_height: int, # Height of measurement instrument in cm above NAP\n",
    "    ) -> gpd.GeoDataFrame: # Cleaned GeoDataFrame with bottom_height column\n",
    "    \"Filter primary survey data, remove duplicates, and calculate bottom height in mNAP\"\n",
    "    return (gdf[gdf[\"survey\"]==\"primary\"]\n",
    "            .groupby(['longitude', 'latitude'], as_index=False).agg(\n",
    "                mean_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"mean\"),\n",
    "                min_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"min\"),\n",
    "                max_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"max\"),\n",
    "                geometry=pd.NamedAgg(column=\"geometry\", aggfunc=\"first\"),\n",
    "                datetime=pd.NamedAgg(column=\"datetime\", aggfunc=\"mean\")\n",
    "            )\n",
    "            .assign(bottom_height=lambda x: msrmnt_height / 100 - x['mean_depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5bd06",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Aggregation of geodataframe returns a pandas dataframe\n",
    "___\n",
    "ðŸ¤” _When I use `clean_gdf` the returned object is a Pandas Dataframe, not a GeoDataFrame. This probably is the result of the `.groupby` method that uses the `agg` method. How can I solve this? I want a GeoDataFrame?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good catch! When you use `.groupby().agg()` on a GeoDataFrame, it returns a regular DataFrame, losing the GeoDataFrame properties.\n",
    "\n",
    "To fix this, you need to convert it back to a GeoDataFrame after the aggregation. You can use:\n",
    "\n",
    "```python\n",
    "gpd.GeoDataFrame(result, geometry='geometry', crs=gdf.crs)\n",
    "```\n",
    "\n",
    "Where `result` is your aggregated dataframe. You'll need to make sure to preserve the original CRS from the input GeoDataFrame.\n",
    "\n",
    "Would you like to try adding this conversion to your `clean_gdf` function?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def clean_gdf(\n",
    "    gdf: gpd.GeoDataFrame, # GeoDataFrame from sl2gdf\n",
    "    msrmnt_height: int, # Height of measurement instrument in cm above NAP\n",
    "    ) -> gpd.GeoDataFrame: # Cleaned GeoDataFrame with bottom_height column\n",
    "    \"Filter primary survey data, remove duplicates, and calculate bottom height in mNAP\"\n",
    "    df_cln = (gdf[gdf[\"survey\"]==\"primary\"]\n",
    "            .groupby(['longitude', 'latitude'], as_index=False).agg(\n",
    "                mean_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"mean\"),\n",
    "                min_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"min\"),\n",
    "                max_depth=pd.NamedAgg(column=\"water_depth\", aggfunc=\"max\"),\n",
    "                geometry=pd.NamedAgg(column=\"geometry\", aggfunc=\"first\"),\n",
    "                datetime=pd.NamedAgg(column=\"datetime\", aggfunc=\"mean\")\n",
    "            )\n",
    "            .assign(bottom_height=lambda x: msrmnt_height / 100 - x['mean_depth']))\n",
    "    return gpd.GeoDataFrame(df_cln, geometry='geometry', crs=gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55583aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cln_gdf = clean_gdf(sl3_gdf, 1823)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8507fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geopandas.geodataframe.GeoDataFrame"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cln_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d9c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>geometry</th>\n",
       "      <th>datetime</th>\n",
       "      <th>bottom_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.076780</td>\n",
       "      <td>52.748757</td>\n",
       "      <td>1.073326</td>\n",
       "      <td>1.069168</td>\n",
       "      <td>1.078859</td>\n",
       "      <td>POINT (201560.979 529268.623)</td>\n",
       "      <td>2022-04-26 11:10:01.221999872</td>\n",
       "      <td>17.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.076780</td>\n",
       "      <td>52.748762</td>\n",
       "      <td>1.068734</td>\n",
       "      <td>1.051482</td>\n",
       "      <td>1.077630</td>\n",
       "      <td>POINT (201560.973 529269.23)</td>\n",
       "      <td>2022-04-26 11:10:00.517230848</td>\n",
       "      <td>17.161266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.076780</td>\n",
       "      <td>52.748768</td>\n",
       "      <td>0.969534</td>\n",
       "      <td>0.867511</td>\n",
       "      <td>1.051482</td>\n",
       "      <td>POINT (201560.967 529269.837)</td>\n",
       "      <td>2022-04-26 11:09:59.692999936</td>\n",
       "      <td>17.260466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.076780</td>\n",
       "      <td>52.748773</td>\n",
       "      <td>0.861626</td>\n",
       "      <td>0.858684</td>\n",
       "      <td>0.867511</td>\n",
       "      <td>POINT (201560.961 529270.444)</td>\n",
       "      <td>2022-04-26 11:09:59.201000192</td>\n",
       "      <td>17.368374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.076789</td>\n",
       "      <td>52.748752</td>\n",
       "      <td>0.958502</td>\n",
       "      <td>0.932471</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>POINT (201561.593 529268.021)</td>\n",
       "      <td>2022-04-26 11:10:02.960588288</td>\n",
       "      <td>17.271498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude  mean_depth  min_depth  max_depth  \\\n",
       "0   6.076780  52.748757    1.073326   1.069168   1.078859   \n",
       "1   6.076780  52.748762    1.068734   1.051482   1.077630   \n",
       "2   6.076780  52.748768    0.969534   0.867511   1.051482   \n",
       "3   6.076780  52.748773    0.861626   0.858684   0.867511   \n",
       "4   6.076789  52.748752    0.958502   0.932471   0.999739   \n",
       "\n",
       "                        geometry                      datetime  bottom_height  \n",
       "0  POINT (201560.979 529268.623) 2022-04-26 11:10:01.221999872      17.156673  \n",
       "1   POINT (201560.973 529269.23) 2022-04-26 11:10:00.517230848      17.161266  \n",
       "2  POINT (201560.967 529269.837) 2022-04-26 11:09:59.692999936      17.260466  \n",
       "3  POINT (201560.961 529270.444) 2022-04-26 11:09:59.201000192      17.368374  \n",
       "4  POINT (201561.593 529268.021) 2022-04-26 11:10:02.960588288      17.271498  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cln_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd9f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201560.97882739094"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cln_gdf['geometry'].iloc[0].x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd859c",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Checking for needed columns\n",
    "___\n",
    "ðŸ¤” _I also would like to check if the Dataframe that is created from the sl2 or sl3 file contains the needed columns in the needed datatype. Should I write a function to check that? Should I add the checks within an existing function? Should I use Pydantic?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good question about validation! You have a few options:\n",
    "\n",
    "1. **Separate validation function** - keeps concerns separated, reusable\n",
    "2. **Add checks within existing functions** - catches issues early where they matter\n",
    "3. **Use Pydantic** - more robust, but adds dependency and complexity\n",
    "\n",
    "For your case, I'd suggest starting simple: add basic checks within your existing functions (like `sl2gdf` or `clean_gdf`) to verify the required columns exist. Something like:\n",
    "\n",
    "```python\n",
    "required_cols = ['longitude', 'latitude', 'water_depth', 'survey']\n",
    "if not all(col in df.columns for col in required_cols):\n",
    "    raise ValueError(f\"Missing required columns...\")\n",
    "```\n",
    "\n",
    "Pydantic would be great if you're building a larger system with complex validation needs, but might be overkill here.\n",
    "\n",
    "Which approach feels right for your use case? Are you expecting the sonar file format to be stable, or do you need robust validation?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def slx2gdf(\n",
    "    sl_filepath: Path, # The absolute location of the file to convert\n",
    "    to_crs: str = \"epsg:28992\", # epsg code of crs to transform the coÃ¶rdinates to\n",
    "    survey_fltr: str = \"primary\", # Filter measurement facts on survey value\n",
    "    )->gpd:\n",
    "    \"Convert a sl2 or sl3 file to a GeoDataFrame with the given crs.\"\n",
    "    s = Sonar(str(sl_filepath))\n",
    "    df = s.df\n",
    "    required_cols = ['longitude', 'latitude', 'water_depth', 'survey']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        raise KeyError(f\"Missing one or more of the required columns in the converted sl2 or sl3 file.\\nRequired columns are: 'longitude', 'latitude', 'water_depth' and 'survey'\")\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n",
    "    gdf = gdf.set_crs(epsg=4326)\n",
    "    return gdf.to_crs(to_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c45be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>survey</th>\n",
       "      <th>datetime</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>min_range</th>\n",
       "      <th>max_range</th>\n",
       "      <th>water_depth</th>\n",
       "      <th>gps_speed</th>\n",
       "      <th>gps_heading</th>\n",
       "      <th>gps_altitude</th>\n",
       "      <th>bottom_index</th>\n",
       "      <th>frames</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>174</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.576000</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>174</td>\n",
       "      <td>secondary</td>\n",
       "      <td>2022-04-26 11:08:49.101999998</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.576000</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>50</td>\n",
       "      <td>[137, 137, 137, 137, 137, 129, 124, 119, 114, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>174</td>\n",
       "      <td>downscan</td>\n",
       "      <td>2022-04-26 11:08:49.239000082</td>\n",
       "      <td>674207</td>\n",
       "      <td>6913400</td>\n",
       "      <td>6.076879</td>\n",
       "      <td>52.748746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.945601</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>38</td>\n",
       "      <td>[152, 152, 152, 152, 129, 143, 140, 137, 140, ...</td>\n",
       "      <td>POINT (201567.685 529267.472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>352</td>\n",
       "      <td>sidescan</td>\n",
       "      <td>2022-04-26 11:08:49.240000010</td>\n",
       "      <td>674207</td>\n",
       "      <td>6913400</td>\n",
       "      <td>6.076879</td>\n",
       "      <td>52.748746</td>\n",
       "      <td>-39.989758</td>\n",
       "      <td>39.989758</td>\n",
       "      <td>0.606861</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.246756</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>21</td>\n",
       "      <td>[42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...</td>\n",
       "      <td>POINT (201567.685 529267.472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>175</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022-04-26 11:08:49.249000072</td>\n",
       "      <td>674208</td>\n",
       "      <td>6913399</td>\n",
       "      <td>6.076888</td>\n",
       "      <td>52.748741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.992880</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.122237</td>\n",
       "      <td>0.247439</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>469</td>\n",
       "      <td>[216, 216, 216, 216, 216, 216, 216, 216, 216, ...</td>\n",
       "      <td>POINT (201568.299 529266.871)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     survey                      datetime       x        y  \\\n",
       "1570  174    primary 2022-04-26 11:08:49.101999998  674208  6913399   \n",
       "1573  174  secondary 2022-04-26 11:08:49.101999998  674208  6913399   \n",
       "1576  174   downscan 2022-04-26 11:08:49.239000082  674207  6913400   \n",
       "1577  352   sidescan 2022-04-26 11:08:49.240000010  674207  6913400   \n",
       "1579  175    primary 2022-04-26 11:08:49.249000072  674208  6913399   \n",
       "\n",
       "      longitude   latitude  min_range  max_range  water_depth  gps_speed  \\\n",
       "1570   6.076888  52.748741   0.000000  36.576000     0.606861   0.127106   \n",
       "1573   6.076888  52.748741   0.000000  36.576000     0.606861   0.127106   \n",
       "1576   6.076879  52.748746   0.000000  21.945601     0.606861   0.127106   \n",
       "1577   6.076879  52.748746 -39.989758  39.989758     0.606861   0.127106   \n",
       "1579   6.076888  52.748741   0.000000   3.992880     0.609836   0.122237   \n",
       "\n",
       "      gps_heading  gps_altitude  bottom_index  \\\n",
       "1570     0.246756         -1.91            50   \n",
       "1573     0.246756         -1.91            50   \n",
       "1576     0.246756         -1.91            38   \n",
       "1577     0.246756         -1.91            21   \n",
       "1579     0.247439         -1.91           469   \n",
       "\n",
       "                                                 frames  \\\n",
       "1570  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...   \n",
       "1573  [137, 137, 137, 137, 137, 129, 124, 119, 114, ...   \n",
       "1576  [152, 152, 152, 152, 129, 143, 140, 137, 140, ...   \n",
       "1577  [42, 26, 41, 38, 43, 46, 43, 47, 50, 50, 53, 5...   \n",
       "1579  [216, 216, 216, 216, 216, 216, 216, 216, 216, ...   \n",
       "\n",
       "                           geometry  \n",
       "1570  POINT (201568.299 529266.871)  \n",
       "1573  POINT (201568.299 529266.871)  \n",
       "1576  POINT (201567.685 529267.472)  \n",
       "1577  POINT (201567.685 529267.472)  \n",
       "1579  POINT (201568.299 529266.871)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = slx2gdf(sl3_f)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:28992>\n",
       "Name: Amersfoort / RD New\n",
       "Axis Info [cartesian]:\n",
       "- X[east]: Easting (metre)\n",
       "- Y[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: Netherlands - onshore, including Waddenzee, Dutch Wadden Islands and 12-mile offshore coastal zone.\n",
       "- bounds: (3.2, 50.75, 7.22, 53.7)\n",
       "Coordinate Operation:\n",
       "- name: RD New\n",
       "- method: Oblique Stereographic\n",
       "Datum: Amersfoort\n",
       "- Ellipsoid: Bessel 1841\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9ba4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201568.2991979634"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf['geometry'].iloc[0].x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc757b2",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Keep x and y coordinates in csv export\n",
    "___\n",
    "ðŸ¤” _I don't want to drop the geometry column completely. I want to keep the x and y coordinates in a x and y column. How do I do that?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "You can extract the x and y coordinates from the geometry column before exporting to CSV. Here's how:\n",
    "\n",
    "```python\n",
    "gdf['x'] = gdf.geometry.x\n",
    "gdf['y'] = gdf.geometry.y\n",
    "```\n",
    "\n",
    "Then when you export to CSV, you can drop just the geometry column:\n",
    "\n",
    "```python\n",
    "gdf.drop(columns='geometry').to_csv(folder_out / f\"{fn}.csv\", index=False)\n",
    "```\n",
    "\n",
    "Would you like to add this to your `export_gdf` function?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def export_gdf(\n",
    "    gdf: gpd.GeoDataFrame, # GeoDataFrame to be saved\n",
    "    fn: str, # Filename of the GeoDataFrame without extension\n",
    "    folder_out: Path, # Absolute path to folder where files can be saved\n",
    "    esri_shp: bool=True, # Save GeoDataFrame to Esri shapefile?\n",
    "    csv: bool=True, # Save GeoDataFrame to comma seperated file?\n",
    "    geopckg: bool=True, # Save GeoDataFrame to geopackage?\n",
    "    ) -> None:\n",
    "    \"Deze functie doet iets\"\n",
    "    if esri_shp: gdf.to_file(folder_out / f\"{fn}.shp\")\n",
    "    if geopckg: gdf.to_file(folder_out / f\"{fn}.gpkg\", driver=\"GPKG\")\n",
    "    if csv:\n",
    "        gdf['x'] = gdf.geometry.x\n",
    "        gdf['y'] = gdf.geometry.y\n",
    "        df = gdf.drop(columns=['geometry'])\n",
    "        df.to_csv(folder_out / f\"{fn}.csv\", index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sonar_2022-04-26_21.07.11beschrijving+0765cmNAP'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl3_f.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0dff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6850/3996915654.py:11: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  if esri_shp: gdf.to_file(folder_out / f\"{fn}.shp\")\n",
      "/home/jelle/code/sonar2csv_shape/.venv/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Field datetime create as date field, though DateTime requested.\n",
      "  ogr_write(\n",
      "/home/jelle/code/sonar2csv_shape/.venv/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'bottom_height' to 'bottom_hei'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "export_gdf(cln_gdf, sl3_f.stem, Path(\"../test/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_sonar_file(\n",
    "    sl_filepath: Path, # Path to sl2 or sl3 file\n",
    "    folder_out: Path, # Output folder for exported files\n",
    "    to_crs: str = \"epsg:28992\" # Target CRS\n",
    "    ) -> None:\n",
    "    \"Process sonar file: extract height, convert to GeoDataFrame, clean, and export\"\n",
    "    msrmnt_height = extract_height(sl_filepath)\n",
    "    gdf = slx2gdf(sl_filepath, to_crs=to_crs)\n",
    "    gdf_clean = clean_gdf(gdf, msrmnt_height)\n",
    "    export_gdf(gdf_clean, sl_filepath.stem, folder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06113e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6850/3996915654.py:11: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  if esri_shp: gdf.to_file(folder_out / f\"{fn}.shp\")\n",
      "/home/jelle/code/sonar2csv_shape/.venv/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Field datetime create as date field, though DateTime requested.\n",
      "  ogr_write(\n",
      "/home/jelle/code/sonar2csv_shape/.venv/lib/python3.11/site-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'bottom_height' to 'bottom_hei'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "process_sonar_file(sl3_f, Path(\"../test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f74017",
   "metadata": {},
   "source": [
    "::: {.callout-tip collapse=\"true\"}\n",
    "## ðŸ¤– AI chat: Difference between `gdf.loc[:, 'y'] =` and `gdf['y'] = `?\n",
    "___\n",
    "ðŸ¤” _Can you explain what the difference is \"under the hood\" between `gdf.loc[:, 'y'] =` and just `gdf['y'] = `?_\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! Here's what's happening under the hood:\n",
    "\n",
    "**`gdf['y'] = ...`** (chained indexing)\n",
    "- Pandas first evaluates `gdf['y']`, which *might* return a view or a copy (pandas can't always tell)\n",
    "- Then it tries to assign to that result\n",
    "- Because pandas isn't sure if you're modifying the original or a copy, it warns you\n",
    "\n",
    "**`gdf.loc[:, 'y'] = ...`** (explicit indexing)\n",
    "- This is a single operation that tells pandas: \"I want to modify the original DataFrame at all rows (`:`) and column `'y'`\"\n",
    "- Pandas knows you intend to modify the original, so no ambiguity, no warning\n",
    "\n",
    "The `.loc[]` approach is more explicit about your intent to modify the DataFrame in place, which helps pandas optimize the operation and avoid unnecessary copies.\n",
    "\n",
    "Does that clarify the difference?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c83ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
